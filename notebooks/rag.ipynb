{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a7c103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HYBRID RAG FUSION SYSTEM\n",
      "==============================\n",
      "Initializing multimodal vulnerability detection...\n",
      "✅ kb1_enriched_dir: /Users/vernetemmanueladjobi/Documents/RessourcesStages/Projets/VulRAG-Hybrid-System/data/processed/kb1\n",
      "✅ kb2_path: /Users/vernetemmanueladjobi/Documents/RessourcesStages/Projets/VulRAG-Hybrid-System/data/tmp/kb2_final_with_embeddings.json\n",
      "✅ kb2_export_dir: /Users/vernetemmanueladjobi/Documents/RessourcesStages/Projets/VulRAG-Hybrid-System/data/tmp/kb2_production_export\n",
      "\n",
      "Fusion Configuration:\n",
      "  KB1 weight: 0.4\n",
      "  KB2 weight: 0.6\n",
      "  Text model: all-MiniLM-L6-v2\n",
      "  Final top-k: 5\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Hybrid RAG Detection & Repair System - Following Original Architecture\n",
    "Pipeline: Code → KB1(3) + KB2(3) → Fusion → Best Match → Context → LLM Detection/Repair → Evaluation Agent\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import requests\n",
    "import openai\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple, Optional, Any\n",
    "from dataclasses import dataclass\n",
    "from collections import Counter\n",
    "import logging\n",
    "import time\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Configurations\n",
    "CONFIG = {\n",
    "    'kb1_enriched_dir': Path.home() / \"Documents/RessourcesStages/Projets/VulRAG-Hybrid-System/data/processed/kb1\",\n",
    "    'kb2_path': Path.home() / \"Documents/RessourcesStages/Projets/VulRAG-Hybrid-System/data/tmp/kb2_final_with_embeddings.json\",\n",
    "    \n",
    "    #  pipeline parameters\n",
    "    'kb1_top_k': 3,              # Exactly 3 candidates from KB1\n",
    "    'kb2_top_k': 3,              # Exactly 3 candidates from KB2  \n",
    "    'fusion_alpha': 0.7,         # Weight for embedding similarity\n",
    "    'fusion_beta': 0.3,          # Weight for feature similarity\n",
    "    'coherence_bonus': 0.1,      # Bonus when both KBs agree\n",
    "    \n",
    "    # LLM configuration\n",
    "    'gpt4_model': 'gpt-4',\n",
    "    'qwen_model': 'qwen2.5-coder:7b',\n",
    "    'ollama_url': 'http://localhost:11434',\n",
    "    \n",
    "    # Text embedding\n",
    "    'text_model': 'all-MiniLM-L6-v2'\n",
    "}\n",
    "\n",
    "@dataclass\n",
    "class KB1Candidate:\n",
    "    \"\"\"KB1 search result candidate\"\"\"\n",
    "    entry_id: str\n",
    "    cve_id: str\n",
    "    similarity_score: float\n",
    "    vulnerability_type: str\n",
    "    fix_strategy_type: str\n",
    "    complexity_level: str\n",
    "    kb2_link_id: Optional[str]\n",
    "    entry_data: Dict\n",
    "\n",
    "@dataclass\n",
    "class KB2Candidate:\n",
    "    \"\"\"KB2 search result candidate\"\"\"\n",
    "    entry_key: str\n",
    "    cve_id: str\n",
    "    similarity_score: float\n",
    "    file_type: str\n",
    "    dangerous_calls: List[str]\n",
    "    graph_stats: Dict\n",
    "    entry_data: Dict\n",
    "\n",
    "@dataclass\n",
    "class FusionResult:\n",
    "    \"\"\"Best match after fusion analysis\"\"\"\n",
    "    cve_id: str\n",
    "    final_score: float\n",
    "    kb1_candidate: Optional[KB1Candidate]\n",
    "    kb2_candidate: Optional[KB2Candidate]\n",
    "    coherence_bonus: float\n",
    "    confidence: float\n",
    "\n",
    "@dataclass\n",
    "class EnrichedContext:\n",
    "    \"\"\"Enriched context from KB1+KB2 jointure\"\"\"\n",
    "    kb1_context: Dict\n",
    "    kb2_context: Dict\n",
    "    structural_insights: Dict\n",
    "    behavioral_patterns: Dict\n",
    "    fix_examples: Dict\n",
    "\n",
    "@dataclass\n",
    "class DetectionResult:\n",
    "    \"\"\"LLM detection task result\"\"\"\n",
    "    is_vulnerable: bool\n",
    "    vulnerability_types: List[str]\n",
    "    confidence_score: float\n",
    "    explanation: str\n",
    "    reasoning: str\n",
    "    llm_model: str\n",
    "\n",
    "@dataclass\n",
    "class RepairResult:\n",
    "    \"\"\"LLM repair task result\"\"\"\n",
    "    fixed_code: str\n",
    "    explanation: str\n",
    "    changes_made: List[str]\n",
    "    fix_strategy: str\n",
    "    llm_model: str\n",
    "\n",
    "@dataclass\n",
    "class EvaluationResult:\n",
    "    \"\"\"Evaluation agent assessment\"\"\"\n",
    "    detection_accuracy: float\n",
    "    repair_quality: float\n",
    "    security_improvement: float\n",
    "    code_functionality: float\n",
    "    overall_score: float\n",
    "    feedback: str\n",
    "\n",
    "print(\"HYBRID RAG DETECTION & REPAIR SYSTEM\")\n",
    "print(\"=\" * 45)\n",
    "print(\"Following YOUR original pipeline architecture...\")\n",
    "print(f\"KB1 candidates: {CONFIG['kb1_top_k']}\")\n",
    "print(f\"KB2 candidates: {CONFIG['kb2_top_k']}\")\n",
    "print(f\"Fusion weights: α={CONFIG['fusion_alpha']}, β={CONFIG['fusion_beta']}\")\n",
    "print(f\"LLM models: GPT-4 baseline + Qwen2.5-coder via Ollama\")\n",
    "\n",
    "# Cell 1: KB1 and KB2 Search Engines (YOUR 3+3 Architecture)\n",
    "\n",
    "class KB1SearchEngine:\n",
    "    \"\"\"\n",
    "    KB1 textual search engine - returns exactly 3 candidates.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, kb1_enriched_dir: Path):\n",
    "        self.kb1_data = {}\n",
    "        self.text_embeddings = {}\n",
    "        self.text_model = SentenceTransformer(CONFIG['text_model'])\n",
    "        \n",
    "        self._load_enriched_kb1(kb1_enriched_dir)\n",
    "        self._compute_text_embeddings()\n",
    "        \n",
    "        logger.info(f\"KB1 Search Engine: {len(self.kb1_data)} entries loaded\")\n",
    "    \n",
    "    def _load_enriched_kb1(self, kb1_dir: Path) -> None:\n",
    "        \"\"\"Load enriched KB1 data\"\"\"\n",
    "        print(\"Loading enriched KB1...\")\n",
    "        cwe_files = list(kb1_dir.glob(\"gpt-4o-mini_CWE-*_enriched.json\"))\n",
    "        \n",
    "        for cwe_file in cwe_files:\n",
    "            with open(cwe_file, 'r') as f:\n",
    "                cwe_data = json.load(f)\n",
    "            \n",
    "            for cve_id, cve_instances in cwe_data.items():\n",
    "                if isinstance(cve_instances, list):\n",
    "                    for idx, instance in enumerate(cve_instances):\n",
    "                        entry_key = f\"{cve_id}_{idx}\"\n",
    "                        self.kb1_data[entry_key] = instance\n",
    "                else:\n",
    "                    self.kb1_data[cve_id] = cve_instances\n",
    "        \n",
    "        print(f\"KB1 loaded: {len(self.kb1_data)} entries\")\n",
    "    \n",
    "    def _compute_text_embeddings(self) -> None:\n",
    "        \"\"\"Precompute text embeddings\"\"\"\n",
    "        print(\"Computing KB1 text embeddings...\")\n",
    "        \n",
    "        for entry_key, entry in self.kb1_data.items():\n",
    "            text_parts = [\n",
    "                entry.get('vulnerability_behavior', {}).get('specific_code_behavior_causing_vulnerability', ''),\n",
    "                entry.get('solution', ''),\n",
    "                entry.get('code_before_change', ''),\n",
    "                entry.get('structural_description', '')\n",
    "            ]\n",
    "            combined_text = ' '.join([part for part in text_parts if part])\n",
    "            embedding = self.text_model.encode([combined_text])[0]\n",
    "            self.text_embeddings[entry_key] = embedding\n",
    "        \n",
    "        print(f\"KB1 embeddings: {len(self.text_embeddings)}\")\n",
    "    \n",
    "    def get_top_3_candidates(self, query_text: str) -> List[KB1Candidate]:\n",
    "        \"\"\"\n",
    "        Get exactly 3 best candidates from KB1.\n",
    "        YOUR pipeline specification.\n",
    "        \"\"\"\n",
    "        \n",
    "        query_embedding = self.text_model.encode([query_text])[0]\n",
    "        \n",
    "        # Calculate similarities\n",
    "        similarities = []\n",
    "        for entry_key, entry_embedding in self.text_embeddings.items():\n",
    "            similarity = np.dot(query_embedding, entry_embedding) / (\n",
    "                np.linalg.norm(query_embedding) * np.linalg.norm(entry_embedding)\n",
    "            )\n",
    "            similarities.append((entry_key, float(similarity)))\n",
    "        \n",
    "        # Get top 3\n",
    "        similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_3 = similarities[:CONFIG['kb1_top_k']]\n",
    "        \n",
    "        # Convert to KB1Candidate objects\n",
    "        candidates = []\n",
    "        for entry_key, similarity in top_3:\n",
    "            entry = self.kb1_data[entry_key]\n",
    "            \n",
    "            candidate = KB1Candidate(\n",
    "                entry_id=entry_key,\n",
    "                cve_id=entry.get('CVE_id', ''),\n",
    "                similarity_score=similarity,\n",
    "                vulnerability_type=entry.get('vulnerability_type', 'unknown'),\n",
    "                fix_strategy_type=entry.get('fix_strategy_type', 'unknown'),\n",
    "                complexity_level=entry.get('complexity_level', 'unknown'),\n",
    "                kb2_link_id=entry.get('kb2_link_id'),\n",
    "                entry_data=entry\n",
    "            )\n",
    "            candidates.append(candidate)\n",
    "        \n",
    "        logger.info(f\"KB1 top-3 candidates: {[c.cve_id for c in candidates]}\")\n",
    "        return candidates\n",
    "\n",
    "\n",
    "class KB2SearchEngine:\n",
    "    \"\"\"\n",
    "    KB2 structural search engine - returns exactly 3 candidates.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, kb2_path: Path):\n",
    "        print(\"Loading KB2...\")\n",
    "        with open(kb2_path, 'r') as f:\n",
    "            self.kb2_data = json.load(f)\n",
    "        \n",
    "        # Build embedding matrix\n",
    "        self.valid_entries = {}\n",
    "        embeddings_list = []\n",
    "        self.entry_keys = []\n",
    "        \n",
    "        for key, entry in self.kb2_data.items():\n",
    "            if entry.get('embedding_computed', False):\n",
    "                self.valid_entries[key] = entry\n",
    "                embeddings_list.append(np.array(entry['graph_embedding'], dtype=np.float32))\n",
    "                self.entry_keys.append(key)\n",
    "        \n",
    "        self.embeddings_matrix = np.vstack(embeddings_list)\n",
    "        logger.info(f\"KB2 Search Engine: {len(self.valid_entries)} entries loaded\")\n",
    "    \n",
    "    def generate_mock_cpg_embedding(self, code: str) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Mock CPG embedding generation for demo.\n",
    "        In production: Code → Joern → CPG → NetworkX → Structural embedding\n",
    "        \"\"\"\n",
    "        # Analyze code patterns\n",
    "        code_lower = code.lower()\n",
    "        features = []\n",
    "        \n",
    "        # Dangerous function detection\n",
    "        dangerous_funcs = ['strcpy', 'strcat', 'sprintf', 'malloc', 'free', 'memcpy', 'gets']\n",
    "        for func in dangerous_funcs:\n",
    "            features.append(1.0 if func in code_lower else 0.0)\n",
    "        \n",
    "        # Code complexity indicators  \n",
    "        features.extend([\n",
    "            len(code.split('\\n')) / 100.0,  # Line count\n",
    "            code.count('{') / 20.0,         # Block count\n",
    "            code.count('*') / 10.0,         # Pointer usage\n",
    "            code.count('if') / 10.0,        # Conditionals\n",
    "            code.count('for') / 10.0        # Loops\n",
    "        ])\n",
    "        \n",
    "        # Pad to 128 dimensions\n",
    "        while len(features) < 128:\n",
    "            features.append(0.0)\n",
    "        features = features[:128]\n",
    "        \n",
    "        # Normalize\n",
    "        embedding = np.array(features, dtype=np.float32)\n",
    "        norm = np.linalg.norm(embedding)\n",
    "        if norm > 0:\n",
    "            embedding = embedding / norm\n",
    "        \n",
    "        return embedding\n",
    "    \n",
    "    def get_top_3_candidates(self, code: str) -> List[KB2Candidate]:\n",
    "        \"\"\"\n",
    "        Get exactly 3 best candidates from KB2.\n",
    "        YOUR pipeline specification.\n",
    "        \"\"\"\n",
    "        \n",
    "        query_embedding = self.generate_mock_cpg_embedding(code)\n",
    "        \n",
    "        # Compute similarities\n",
    "        similarities = np.dot(self.embeddings_matrix, query_embedding)\n",
    "        \n",
    "        # Get top 3 indices\n",
    "        top_3_indices = np.argsort(similarities)[-CONFIG['kb2_top_k']:][::-1]\n",
    "        \n",
    "        # Convert to KB2Candidate objects\n",
    "        candidates = []\n",
    "        for idx in top_3_indices:\n",
    "            entry_key = self.entry_keys[idx]\n",
    "            entry = self.valid_entries[entry_key]\n",
    "            similarity = float(similarities[idx])\n",
    "            \n",
    "            candidate = KB2Candidate(\n",
    "                entry_key=entry_key,\n",
    "                cve_id=entry.get('cve_id', ''),\n",
    "                similarity_score=similarity,\n",
    "                file_type=entry.get('file_type', 'unknown'),\n",
    "                dangerous_calls=list(entry.get('features', {}).get('security_features', {}).get('dangerous_calls', {}).keys()),\n",
    "                graph_stats=entry.get('graph_statistics', {}),\n",
    "                entry_data=entry\n",
    "            )\n",
    "            candidates.append(candidate)\n",
    "        \n",
    "        logger.info(f\"KB2 top-3 candidates: {[c.cve_id for c in candidates]}\")\n",
    "        return candidates\n",
    "\n",
    "\n",
    "# Initialize search engines\n",
    "print(\"\\nInitializing search engines...\")\n",
    "kb1_engine = KB1SearchEngine(CONFIG['kb1_enriched_dir'])\n",
    "kb2_engine = KB2SearchEngine(CONFIG['kb2_path'])\n",
    "\n",
    "# Cell 2: Fusion Analysis Engine (YOUR Architecture)\n",
    "\n",
    "class FusionAnalysisEngine:\n",
    "    \"\"\"\n",
    "    Fusion analysis following YOUR exact pipeline.\n",
    "    \n",
    "    Input: 3 KB1 candidates + 3 KB2 candidates\n",
    "    Output: 1 best match with enriched context\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        logger.info(\"Fusion Analysis Engine initialized\")\n",
    "    \n",
    "    def analyze_fusion(self, kb1_candidates: List[KB1Candidate], \n",
    "                      kb2_candidates: List[KB2Candidate]) -> FusionResult:\n",
    "        \"\"\"\n",
    "        YOUR fusion algorithm: find best match from 3+3 candidates.\n",
    "        \n",
    "        Strategy:\n",
    "        1. Cross-match by CVE ID when possible\n",
    "        2. Weighted scoring with coherence bonus\n",
    "        3. Return single best match\n",
    "        \"\"\"\n",
    "        \n",
    "        print(\"Running fusion analysis...\")\n",
    "        \n",
    "        # Create all possible candidate combinations\n",
    "        fusion_scores = []\n",
    "        \n",
    "        # Strategy 1: Direct CVE matches (highest priority)\n",
    "        kb1_cves = {c.cve_id: c for c in kb1_candidates if c.cve_id}\n",
    "        kb2_cves = {c.cve_id: c for c in kb2_candidates if c.cve_id}\n",
    "        \n",
    "        common_cves = set(kb1_cves.keys()) & set(kb2_cves.keys())\n",
    "        \n",
    "        for cve_id in common_cves:\n",
    "            kb1_cand = kb1_cves[cve_id]\n",
    "            kb2_cand = kb2_cves[cve_id]\n",
    "            \n",
    "            # Weighted fusion score\n",
    "            final_score = (CONFIG['fusion_alpha'] * kb1_cand.similarity_score + \n",
    "                          CONFIG['fusion_beta'] * kb2_cand.similarity_score)\n",
    "            \n",
    "            # Coherence bonus for same CVE\n",
    "            coherence_bonus = CONFIG['coherence_bonus']\n",
    "            final_score += coherence_bonus\n",
    "            \n",
    "            confidence = min((kb1_cand.similarity_score + kb2_cand.similarity_score) / 2 + coherence_bonus, 1.0)\n",
    "            \n",
    "            fusion_scores.append((final_score, cve_id, kb1_cand, kb2_cand, coherence_bonus, confidence))\n",
    "        \n",
    "        # Strategy 2: If no direct matches, cross-product all combinations\n",
    "        if not fusion_scores:\n",
    "            for kb1_cand in kb1_candidates:\n",
    "                for kb2_cand in kb2_candidates:\n",
    "                    # Check if CVEs are related (same base)\n",
    "                    kb1_base = kb1_cand.cve_id.split('_')[0] if '_' in kb1_cand.cve_id else kb1_cand.cve_id\n",
    "                    kb2_base = kb2_cand.cve_id.split('_')[0] if '_' in kb2_cand.cve_id else kb2_cand.cve_id\n",
    "                    \n",
    "                    base_bonus = 0.05 if kb1_base == kb2_base else 0.0\n",
    "                    \n",
    "                    final_score = (CONFIG['fusion_alpha'] * kb1_cand.similarity_score + \n",
    "                                  CONFIG['fusion_beta'] * kb2_cand.similarity_score + base_bonus)\n",
    "                    \n",
    "                    confidence = (kb1_cand.similarity_score + kb2_cand.similarity_score) / 2\n",
    "                    \n",
    "                    fusion_scores.append((final_score, kb1_cand.cve_id, kb1_cand, kb2_cand, base_bonus, confidence))\n",
    "        \n",
    "        # Strategy 3: KB1 only or KB2 only (fallback)\n",
    "        if not fusion_scores:\n",
    "            # Best KB1 candidate only\n",
    "            best_kb1 = kb1_candidates[0] if kb1_candidates else None\n",
    "            if best_kb1:\n",
    "                fusion_scores.append((best_kb1.similarity_score, best_kb1.cve_id, best_kb1, None, 0.0, best_kb1.similarity_score))\n",
    "            \n",
    "            # Best KB2 candidate only\n",
    "            best_kb2 = kb2_candidates[0] if kb2_candidates else None\n",
    "            if best_kb2:\n",
    "                fusion_scores.append((best_kb2.similarity_score, best_kb2.cve_id, None, best_kb2, 0.0, best_kb2.similarity_score))\n",
    "        \n",
    "        # Select best fusion result\n",
    "        if fusion_scores:\n",
    "            fusion_scores.sort(key=lambda x: x[0], reverse=True)\n",
    "            best_score, cve_id, kb1_cand, kb2_cand, coherence_bonus, confidence = fusion_scores[0]\n",
    "            \n",
    "            result = FusionResult(\n",
    "                cve_id=cve_id,\n",
    "                final_score=best_score,\n",
    "                kb1_candidate=kb1_cand,\n",
    "                kb2_candidate=kb2_cand,\n",
    "                coherence_bonus=coherence_bonus,\n",
    "                confidence=confidence\n",
    "            )\n",
    "            \n",
    "            print(f\"Fusion result: {cve_id} (score: {best_score:.3f}, confidence: {confidence:.3f})\")\n",
    "            return result\n",
    "        \n",
    "        # No valid fusion found\n",
    "        return FusionResult(\n",
    "            cve_id=\"NO_MATCH\",\n",
    "            final_score=0.0,\n",
    "            kb1_candidate=None,\n",
    "            kb2_candidate=None,\n",
    "            coherence_bonus=0.0,\n",
    "            confidence=0.0\n",
    "        )\n",
    "    \n",
    "    def build_enriched_context(self, fusion_result: FusionResult) -> EnrichedContext:\n",
    "        \"\"\"\n",
    "        Build enriched context via KB1+KB2 jointure.\n",
    "        YOUR pipeline: context from both KBs via jointure ID.\n",
    "        \"\"\"\n",
    "        \n",
    "        print(\"Building enriched context via KB1+KB2 jointure...\")\n",
    "        \n",
    "        kb1_context = {}\n",
    "        kb2_context = {}\n",
    "        structural_insights = {}\n",
    "        behavioral_patterns = {}\n",
    "        fix_examples = {}\n",
    "        \n",
    "        # Extract KB1 context\n",
    "        if fusion_result.kb1_candidate:\n",
    "            kb1_data = fusion_result.kb1_candidate.entry_data\n",
    "            \n",
    "            kb1_context = {\n",
    "                'vulnerability_behavior': kb1_data.get('vulnerability_behavior', {}),\n",
    "                'solution': kb1_data.get('solution', ''),\n",
    "                'gpt_analysis': kb1_data.get('GPT_analysis', ''),\n",
    "                'vulnerability_type': fusion_result.kb1_candidate.vulnerability_type,\n",
    "                'fix_strategy_type': fusion_result.kb1_candidate.fix_strategy_type,\n",
    "                'complexity_level': fusion_result.kb1_candidate.complexity_level,\n",
    "                'structural_description': kb1_data.get('structural_description', '')\n",
    "            }\n",
    "            \n",
    "            fix_examples = {\n",
    "                'code_before': kb1_data.get('code_before_change', ''),\n",
    "                'code_after': kb1_data.get('code_after_change', ''),\n",
    "                'modified_lines': kb1_data.get('modified_lines', {})\n",
    "            }\n",
    "            \n",
    "            behavioral_patterns = kb1_data.get('vulnerability_behavior', {})\n",
    "        \n",
    "        # Extract KB2 context  \n",
    "        if fusion_result.kb2_candidate:\n",
    "            kb2_data = fusion_result.kb2_candidate.entry_data\n",
    "            \n",
    "            kb2_context = {\n",
    "                'cve_id': fusion_result.kb2_candidate.cve_id,\n",
    "                'file_type': fusion_result.kb2_candidate.file_type,\n",
    "                'dangerous_calls': fusion_result.kb2_candidate.dangerous_calls,\n",
    "                'graph_statistics': fusion_result.kb2_candidate.graph_stats,\n",
    "                'security_features': kb2_data.get('features', {}).get('security_features', {}),\n",
    "                'complexity_metrics': kb2_data.get('features', {}).get('complexity_metrics', {}),\n",
    "                'code_patterns': kb2_data.get('features', {}).get('code_patterns', {})\n",
    "            }\n",
    "            \n",
    "            structural_insights = {\n",
    "                'dangerous_functions_detected': fusion_result.kb2_candidate.dangerous_calls,\n",
    "                'graph_complexity': fusion_result.kb2_candidate.graph_stats,\n",
    "                'has_memory_operations': any(call in fusion_result.kb2_candidate.dangerous_calls \n",
    "                                           for call in ['malloc', 'free', 'calloc', 'realloc']),\n",
    "                'has_string_operations': any(call in fusion_result.kb2_candidate.dangerous_calls \n",
    "                                           for call in ['strcpy', 'strcat', 'sprintf', 'gets']),\n",
    "                'complexity_level': 'high' if fusion_result.kb2_candidate.graph_stats.get('nodes', 0) > 200 else 'medium'\n",
    "            }\n",
    "        \n",
    "        enriched_context = EnrichedContext(\n",
    "            kb1_context=kb1_context,\n",
    "            kb2_context=kb2_context,\n",
    "            structural_insights=structural_insights,\n",
    "            behavioral_patterns=behavioral_patterns,\n",
    "            fix_examples=fix_examples\n",
    "        )\n",
    "        \n",
    "        print(\"Enriched context built successfully\")\n",
    "        return enriched_context\n",
    "\n",
    "\n",
    "# Initialize fusion engine\n",
    "fusion_engine = FusionAnalysisEngine()\n",
    "\n",
    "print(\"✅ Phase 1 complete: KB1+KB2 search engines and fusion analysis ready\")\n",
    "print(\"Next: LLM Detection/Repair + Evaluation Agent...\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vulrag_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
