{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71cda2d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KB1 ENRICHMENT WITH KB2 STRUCTURAL DATA\n",
      "=============================================\n",
      "Loading KB1 and KB2 data for cross-reference...\n",
      "✅ Found: kb1_directory at /Users/vernetemmanueladjobi/Documents/RessourcesStages/Projets/VulRAG-Hybrid-System/data/raw/vulrag_kb\n",
      "✅ Found: kb2_path at /Users/vernetemmanueladjobi/Documents/RessourcesStages/Projets/VulRAG-Hybrid-System/data/tmp/kb2_final_with_embeddings.json\n",
      "✅ Found: output_directory at /Users/vernetemmanueladjobi/Documents/RessourcesStages/Projets/VulRAG-Hybrid-System/data/processed/kb1\n",
      "\n",
      "Configuration loaded successfully\n",
      "  kb1_directory: /Users/vernetemmanueladjobi/Documents/RessourcesStages/Projets/VulRAG-Hybrid-System/data/raw/vulrag_kb\n",
      "  kb2_path: /Users/vernetemmanueladjobi/Documents/RessourcesStages/Projets/VulRAG-Hybrid-System/data/tmp/kb2_final_with_embeddings.json\n",
      "  output_directory: /Users/vernetemmanueladjobi/Documents/RessourcesStages/Projets/VulRAG-Hybrid-System/data/processed/kb1\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "KB1 Enrichment using KB2 Structural Analysis\n",
    "Adds 5 missing fields to KB1 for hybrid RAG fusion\n",
    "Scientific approach: Leverage KB2 structural insights to enhance KB1 textual entries\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "from collections import Counter\n",
    "import logging\n",
    "from dataclasses import dataclass\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Configuration paths\n",
    "CONFIG = {\n",
    "    'kb1_directory': Path.home() / \"Documents/RessourcesStages/Projets/VulRAG-Hybrid-System/data/raw/vulrag_kb\",\n",
    "    'kb2_path': Path.home() / \"Documents/RessourcesStages/Projets/VulRAG-Hybrid-System/data/tmp/kb2_final_with_embeddings.json\",\n",
    "    'output_directory': Path.home() / \"Documents/RessourcesStages/Projets/VulRAG-Hybrid-System/data/processed/kb1\"\n",
    "}\n",
    "\n",
    "@dataclass\n",
    "class EnrichmentMapping:\n",
    "    \"\"\"Data class for KB1-KB2 mapping results\"\"\"\n",
    "    kb1_cve_id: str\n",
    "    kb2_entry_key: str\n",
    "    kb2_data: Dict\n",
    "    mapping_confidence: float\n",
    "\n",
    "print(\"KB1 ENRICHMENT WITH KB2 STRUCTURAL DATA\")\n",
    "print(\"=\" * 45)\n",
    "print(\"Loading KB1 and KB2 data for cross-reference...\")\n",
    "\n",
    "# Validate paths\n",
    "for key, path in CONFIG.items():\n",
    "    if not path.exists():\n",
    "        print(f\"⚠️  Warning: {key} path does not exist: {path}\")\n",
    "    else:\n",
    "        print(f\"✅ Found: {key} at {path}\")\n",
    "\n",
    "print(f\"\\nConfiguration loaded successfully\")\n",
    "for key, value in CONFIG.items():\n",
    "    print(f\"  {key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37798a0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading KB1 from 10 CWE files...\n",
      "  CWE-125: 140 entries loaded\n",
      "  CWE-787: 187 entries loaded\n",
      "  CWE-20: 182 entries loaded\n",
      "  CWE-264: 120 entries loaded\n",
      "  CWE-416: 660 entries loaded\n",
      "  CWE-401: 101 entries loaded\n",
      "  CWE-476: 281 entries loaded\n",
      "  CWE-362: 320 entries loaded\n",
      "  CWE-119: 173 entries loaded\n",
      "  CWE-200: 153 entries loaded\n",
      "Total KB1 entries loaded: 2205\n",
      "Loading KB2 from: /Users/vernetemmanueladjobi/Documents/RessourcesStages/Projets/VulRAG-Hybrid-System/data/tmp/kb2_final_with_embeddings.json\n",
      "KB2 entries loaded: 4410 (with embeddings)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Cell 1: Load KB1 and KB2 Data\n",
    "\n",
    "def load_kb1_data(kb1_directory: Path) -> Dict[str, Dict]:\n",
    "    \"\"\"\n",
    "    Load all KB1 CWE files and organize by CVE_id.\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary mapping CVE_id to KB1 entry data\n",
    "        \n",
    "    Scientific approach:\n",
    "        - Consolidate multiple CWE files into unified structure\n",
    "        - Preserve original CWE classification\n",
    "        - Handle duplicate CVE_ids across different CWEs\n",
    "    \"\"\"\n",
    "    \n",
    "    kb1_data = {}\n",
    "    cwe_files = list(kb1_directory.glob(\"gpt-4o-mini_CWE-*.json\"))\n",
    "    \n",
    "    print(f\"Loading KB1 from {len(cwe_files)} CWE files...\")\n",
    "    \n",
    "    for cwe_file in cwe_files:\n",
    "        cwe_name = cwe_file.stem.split('_')[1]  # Extract CWE-XXX\n",
    "        \n",
    "        try:\n",
    "            with open(cwe_file, 'r') as f:\n",
    "                cwe_data = json.load(f)\n",
    "            \n",
    "            entry_count = 0\n",
    "            for cve_id, cve_instances in cwe_data.items():\n",
    "                if isinstance(cve_instances, list):\n",
    "                    for idx, instance in enumerate(cve_instances):\n",
    "                        # Create unique key for each instance\n",
    "                        instance_key = f\"{cve_id}_{idx}\"\n",
    "                        \n",
    "                        # Add CWE metadata\n",
    "                        instance['source_cwe'] = cwe_name\n",
    "                        instance['instance_index'] = idx\n",
    "                        instance['total_instances'] = len(cve_instances)\n",
    "                        \n",
    "                        kb1_data[instance_key] = instance\n",
    "                        entry_count += 1\n",
    "                else:\n",
    "                    # Single instance\n",
    "                    cve_instances['source_cwe'] = cwe_name\n",
    "                    cve_instances['instance_index'] = 0\n",
    "                    cve_instances['total_instances'] = 1\n",
    "                    kb1_data[cve_id] = cve_instances\n",
    "                    entry_count += 1\n",
    "            \n",
    "            print(f\"  {cwe_name}: {entry_count} entries loaded\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to load {cwe_file}: {e}\")\n",
    "    \n",
    "    print(f\"Total KB1 entries loaded: {len(kb1_data)}\")\n",
    "    return kb1_data\n",
    "\n",
    "def load_kb2_data(kb2_path: Path) -> Dict[str, Dict]:\n",
    "    \"\"\"\n",
    "    Load KB2 data with structural embeddings.\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary of KB2 entries organized by entry_key\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"Loading KB2 from: {kb2_path}\")\n",
    "    \n",
    "    with open(kb2_path, 'r') as f:\n",
    "        kb2_data = json.load(f)\n",
    "    \n",
    "    # Filter entries with valid embeddings\n",
    "    valid_kb2 = {}\n",
    "    for key, entry in kb2_data.items():\n",
    "        if entry.get('embedding_computed', False):\n",
    "            valid_kb2[key] = entry\n",
    "    \n",
    "    print(f\"KB2 entries loaded: {len(valid_kb2)} (with embeddings)\")\n",
    "    return valid_kb2\n",
    "\n",
    "# Execute loading\n",
    "kb1_data = load_kb1_data(CONFIG['kb1_directory'])\n",
    "kb2_data = load_kb2_data(CONFIG['kb2_path'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f55b9f7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANALYZING CVE MAPPING BETWEEN KB1 AND KB2\n",
      "=============================================\n",
      "KB1 CVEs: 1154\n",
      "KB2 CVEs: 1154\n",
      "Exact matches: 1154\n",
      "Overlap: 100.0%\n",
      "KB1 only: 0\n",
      "KB2 only: 0\n",
      "\n",
      "Sample exact matches:\n",
      "  1. CVE-2006-3635\n",
      "  2. CVE-2007-6761\n",
      "  3. CVE-2007-6762\n",
      "  4. CVE-2008-7316\n",
      "  5. CVE-2009-2692\n",
      "\n",
      "Created 2205 KB1-KB2 mappings\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Cell 2: CVE Mapping Analysis\n",
    "\n",
    "def analyze_cve_mapping(kb1_data: Dict, kb2_data: Dict) -> Dict:\n",
    "    \"\"\"\n",
    "    Analyze CVE overlap between KB1 and KB2.\n",
    "    \n",
    "    Scientific approach:\n",
    "        - Identify exact CVE matches\n",
    "        - Handle version variations (CVE-XXXX-XXXX vs CVE-XXXX-XXXX_X)\n",
    "        - Quantify mapping coverage and confidence\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"ANALYZING CVE MAPPING BETWEEN KB1 AND KB2\")\n",
    "    print(\"=\" * 45)\n",
    "    \n",
    "    # Extract CVE IDs from both datasets\n",
    "    kb1_cves = set()\n",
    "    for key, entry in kb1_data.items():\n",
    "        cve_id = entry.get('CVE_id', '')\n",
    "        if cve_id:\n",
    "            kb1_cves.add(cve_id)\n",
    "    \n",
    "    kb2_cves = set()\n",
    "    for key, entry in kb2_data.items():\n",
    "        cve_id = entry.get('cve_id', '')\n",
    "        if cve_id:\n",
    "            # Handle KB2 format: CVE-XXXX-XXXX_X\n",
    "            base_cve = cve_id.split('_')[0] if '_' in cve_id else cve_id\n",
    "            kb2_cves.add(base_cve)\n",
    "    \n",
    "    # Analyze overlap\n",
    "    exact_matches = kb1_cves & kb2_cves\n",
    "    kb1_only = kb1_cves - kb2_cves\n",
    "    kb2_only = kb2_cves - kb1_cves\n",
    "    \n",
    "    mapping_stats = {\n",
    "        'kb1_total_cves': len(kb1_cves),\n",
    "        'kb2_total_cves': len(kb2_cves),\n",
    "        'exact_matches': len(exact_matches),\n",
    "        'kb1_only': len(kb1_only),\n",
    "        'kb2_only': len(kb2_only),\n",
    "        'overlap_percentage': len(exact_matches) / len(kb1_cves) * 100 if kb1_cves else 0\n",
    "    }\n",
    "    \n",
    "    print(f\"KB1 CVEs: {mapping_stats['kb1_total_cves']}\")\n",
    "    print(f\"KB2 CVEs: {mapping_stats['kb2_total_cves']}\")\n",
    "    print(f\"Exact matches: {mapping_stats['exact_matches']}\")\n",
    "    print(f\"Overlap: {mapping_stats['overlap_percentage']:.1f}%\")\n",
    "    print(f\"KB1 only: {mapping_stats['kb1_only']}\")\n",
    "    print(f\"KB2 only: {mapping_stats['kb2_only']}\")\n",
    "    \n",
    "    # Show sample matches\n",
    "    print(f\"\\nSample exact matches:\")\n",
    "    for i, cve in enumerate(sorted(exact_matches)[:5]):\n",
    "        print(f\"  {i+1}. {cve}\")\n",
    "    \n",
    "    return mapping_stats, exact_matches\n",
    "\n",
    "def create_kb1_kb2_mappings(kb1_data: Dict, kb2_data: Dict, exact_matches: set) -> List[EnrichmentMapping]:\n",
    "    \"\"\"\n",
    "    Create detailed mappings between KB1 and KB2 entries.\n",
    "    \n",
    "    Returns:\n",
    "        List of EnrichmentMapping objects for successful matches\n",
    "    \"\"\"\n",
    "    \n",
    "    mappings = []\n",
    "    \n",
    "    for kb1_key, kb1_entry in kb1_data.items():\n",
    "        kb1_cve = kb1_entry.get('CVE_id', '')\n",
    "        \n",
    "        if kb1_cve in exact_matches:\n",
    "            # Find corresponding KB2 entries (both vuln and patch)\n",
    "            kb2_candidates = []\n",
    "            \n",
    "            for kb2_key, kb2_entry in kb2_data.items():\n",
    "                kb2_cve = kb2_entry.get('cve_id', '').split('_')[0]\n",
    "                \n",
    "                if kb2_cve == kb1_cve:\n",
    "                    kb2_candidates.append((kb2_key, kb2_entry))\n",
    "            \n",
    "            if kb2_candidates:\n",
    "                # Prefer vulnerable version for analysis, fallback to patch\n",
    "                vuln_entry = None\n",
    "                patch_entry = None\n",
    "                \n",
    "                for kb2_key, kb2_entry in kb2_candidates:\n",
    "                    if kb2_entry.get('file_type') == 'vuln':\n",
    "                        vuln_entry = (kb2_key, kb2_entry)\n",
    "                    elif kb2_entry.get('file_type') == 'patch':\n",
    "                        patch_entry = (kb2_key, kb2_entry)\n",
    "                \n",
    "                # Choose best candidate\n",
    "                chosen_entry = vuln_entry if vuln_entry else patch_entry\n",
    "                \n",
    "                if chosen_entry:\n",
    "                    kb2_key, kb2_entry = chosen_entry\n",
    "                    \n",
    "                    mapping = EnrichmentMapping(\n",
    "                        kb1_cve_id=kb1_key,\n",
    "                        kb2_entry_key=kb2_key,\n",
    "                        kb2_data=kb2_entry,\n",
    "                        mapping_confidence=1.0  # Exact CVE match\n",
    "                    )\n",
    "                    mappings.append(mapping)\n",
    "    \n",
    "    print(f\"\\nCreated {len(mappings)} KB1-KB2 mappings\")\n",
    "    return mappings\n",
    "\n",
    "# Execute mapping analysis\n",
    "mapping_stats, exact_matches = analyze_cve_mapping(kb1_data, kb2_data)\n",
    "kb1_kb2_mappings = create_kb1_kb2_mappings(kb1_data, kb2_data, exact_matches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1264c11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing field generation on: CVE-2014-7825_0\n",
      "KB2 link: CVE-2014-7825_0_vuln\n",
      "Dangerous calls found: []\n",
      "Generated vulnerability type: race_condition\n",
      "Generated fix strategy: bounds_checking\n",
      "Generated complexity: simple\n",
      "Structural description: Medium-sized code structure with 118 nodes; moderate control flow with 5 control structures; high fu...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Cell 3: Generate New Fields from KB2 Data\n",
    "\n",
    "def analyze_structural_patterns(kb2_entry: Dict) -> Dict:\n",
    "    \"\"\"\n",
    "    Extract structural insights from KB2 entry for KB1 enrichment.\n",
    "    \n",
    "    Args:\n",
    "        kb2_entry: KB2 entry with features and embeddings\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary of extracted structural patterns\n",
    "    \"\"\"\n",
    "    \n",
    "    features = kb2_entry.get('features', {})\n",
    "    security_features = features.get('security_features', {})\n",
    "    complexity_metrics = features.get('complexity_metrics', {})\n",
    "    code_patterns = features.get('code_patterns', {})\n",
    "    \n",
    "    # Extract dangerous calls\n",
    "    dangerous_calls = list(security_features.get('dangerous_calls', {}).keys())\n",
    "    \n",
    "    # Analyze complexity\n",
    "    edge_density = complexity_metrics.get('edge_density', 0)\n",
    "    call_density = complexity_metrics.get('call_to_vertex_ratio', 0)\n",
    "    \n",
    "    # Get graph statistics\n",
    "    graph_stats = kb2_entry.get('graph_statistics', {})\n",
    "    node_count = graph_stats.get('nodes', 0)\n",
    "    edge_count = graph_stats.get('edges', 0)\n",
    "    \n",
    "    return {\n",
    "        'dangerous_calls': dangerous_calls,\n",
    "        'edge_density': edge_density,\n",
    "        'call_density': call_density,\n",
    "        'node_count': node_count,\n",
    "        'edge_count': edge_count,\n",
    "        'vertex_types': code_patterns.get('vertex_type_distribution', {}),\n",
    "        'all_calls': list(code_patterns.get('all_calls', {}).keys())\n",
    "    }\n",
    "\n",
    "def generate_vulnerability_type(kb1_entry: Dict, structural_patterns: Dict) -> str:\n",
    "    \"\"\"\n",
    "    Determine vulnerability type based on KB1 textual data and KB2 structural patterns.\n",
    "    \n",
    "    Scientific approach:\n",
    "        - Combine textual analysis from KB1 \n",
    "        - Structural pattern recognition from KB2\n",
    "        - Rule-based classification with confidence scoring\n",
    "    \"\"\"\n",
    "    \n",
    "    # Extract textual indicators from KB1\n",
    "    vulnerability_behavior = kb1_entry.get('vulnerability_behavior', {})\n",
    "    code_before = kb1_entry.get('code_before_change', '').lower()\n",
    "    solution = kb1_entry.get('solution', '').lower()\n",
    "    \n",
    "    # Combine all text for analysis\n",
    "    text_content = ' '.join([\n",
    "        vulnerability_behavior.get('specific_code_behavior_causing_vulnerability', ''),\n",
    "        code_before,\n",
    "        solution\n",
    "    ]).lower()\n",
    "    \n",
    "    # Structural indicators from KB2\n",
    "    dangerous_calls = structural_patterns.get('dangerous_calls', [])\n",
    "    \n",
    "    # Classification rules\n",
    "    if any(call in dangerous_calls for call in ['strcpy', 'strcat', 'sprintf', 'gets']):\n",
    "        if 'buffer' in text_content or 'overflow' in text_content:\n",
    "            return 'buffer_overflow'\n",
    "    \n",
    "    if any(call in dangerous_calls for call in ['malloc', 'calloc', 'realloc', 'free']):\n",
    "        if 'use after free' in text_content or 'double free' in text_content:\n",
    "            return 'use_after_free'\n",
    "        elif 'memory leak' in text_content or 'leak' in text_content:\n",
    "            return 'memory_leak'\n",
    "    \n",
    "    if 'null' in text_content and 'pointer' in text_content:\n",
    "        return 'null_pointer_dereference'\n",
    "    \n",
    "    if 'race' in text_content or 'concurrent' in text_content:\n",
    "        return 'race_condition'\n",
    "    \n",
    "    if 'injection' in text_content or 'input' in text_content:\n",
    "        return 'injection'\n",
    "    \n",
    "    if 'privilege' in text_content or 'permission' in text_content:\n",
    "        return 'privilege_escalation'\n",
    "    \n",
    "    # Default based on CWE\n",
    "    cwe = kb1_entry.get('source_cwe', '')\n",
    "    cwe_mapping = {\n",
    "        'CWE-119': 'buffer_overflow',\n",
    "        'CWE-125': 'buffer_overflow', \n",
    "        'CWE-787': 'buffer_overflow',\n",
    "        'CWE-416': 'use_after_free',\n",
    "        'CWE-401': 'memory_leak',\n",
    "        'CWE-476': 'null_pointer_dereference',\n",
    "        'CWE-362': 'race_condition',\n",
    "        'CWE-20': 'input_validation',\n",
    "        'CWE-200': 'information_disclosure',\n",
    "        'CWE-264': 'privilege_escalation'\n",
    "    }\n",
    "    \n",
    "    return cwe_mapping.get(cwe, 'other')\n",
    "\n",
    "def generate_fix_strategy_type(kb1_entry: Dict, structural_patterns: Dict) -> str:\n",
    "    \"\"\"\n",
    "    Determine fix strategy based on vulnerability analysis.\n",
    "    \"\"\"\n",
    "    \n",
    "    solution = kb1_entry.get('solution', '').lower()\n",
    "    vulnerability_type = generate_vulnerability_type(kb1_entry, structural_patterns)\n",
    "    \n",
    "    # Strategy mapping based on vulnerability type and solution text\n",
    "    if 'bounds' in solution or 'check' in solution or 'validate' in solution:\n",
    "        return 'bounds_checking'\n",
    "    \n",
    "    if 'sanitize' in solution or 'filter' in solution or 'escape' in solution:\n",
    "        return 'input_validation'\n",
    "    \n",
    "    if 'lock' in solution or 'mutex' in solution or 'synchroniz' in solution:\n",
    "        return 'synchronization'\n",
    "    \n",
    "    if 'null' in solution and 'check' in solution:\n",
    "        return 'null_checking'\n",
    "    \n",
    "    if 'free' in solution or 'cleanup' in solution:\n",
    "        return 'resource_management'\n",
    "    \n",
    "    # Default mapping by vulnerability type\n",
    "    strategy_mapping = {\n",
    "        'buffer_overflow': 'bounds_checking',\n",
    "        'use_after_free': 'resource_management', \n",
    "        'memory_leak': 'resource_management',\n",
    "        'null_pointer_dereference': 'null_checking',\n",
    "        'race_condition': 'synchronization',\n",
    "        'injection': 'input_validation',\n",
    "        'privilege_escalation': 'access_control'\n",
    "    }\n",
    "    \n",
    "    return strategy_mapping.get(vulnerability_type, 'other')\n",
    "\n",
    "def generate_complexity_level(structural_patterns: Dict) -> str:\n",
    "    \"\"\"\n",
    "    Determine complexity level based on structural metrics.\n",
    "    \n",
    "    Scientific approach:\n",
    "        - Graph complexity metrics (nodes, edges, density)\n",
    "        - Call complexity (dangerous calls, total calls)\n",
    "        - Threshold-based classification\n",
    "    \"\"\"\n",
    "    \n",
    "    node_count = structural_patterns.get('node_count', 0)\n",
    "    edge_density = structural_patterns.get('edge_density', 0)\n",
    "    dangerous_calls_count = len(structural_patterns.get('dangerous_calls', []))\n",
    "    \n",
    "    # Complexity scoring\n",
    "    complexity_score = 0\n",
    "    \n",
    "    # Node count contribution\n",
    "    if node_count > 500:\n",
    "        complexity_score += 3\n",
    "    elif node_count > 200:\n",
    "        complexity_score += 2\n",
    "    elif node_count > 50:\n",
    "        complexity_score += 1\n",
    "    \n",
    "    # Edge density contribution\n",
    "    if edge_density > 10:\n",
    "        complexity_score += 2\n",
    "    elif edge_density > 5:\n",
    "        complexity_score += 1\n",
    "    \n",
    "    # Dangerous calls contribution\n",
    "    if dangerous_calls_count > 5:\n",
    "        complexity_score += 2\n",
    "    elif dangerous_calls_count > 2:\n",
    "        complexity_score += 1\n",
    "    \n",
    "    # Classification\n",
    "    if complexity_score >= 6:\n",
    "        return 'complex'\n",
    "    elif complexity_score >= 3:\n",
    "        return 'moderate'\n",
    "    else:\n",
    "        return 'simple'\n",
    "\n",
    "def generate_structural_description(kb1_entry: Dict, structural_patterns: Dict) -> str:\n",
    "    \"\"\"\n",
    "    Generate human-readable structural description combining KB1 and KB2 insights.\n",
    "    \"\"\"\n",
    "    \n",
    "    dangerous_calls = structural_patterns.get('dangerous_calls', [])\n",
    "    node_count = structural_patterns.get('node_count', 0)\n",
    "    vertex_types = structural_patterns.get('vertex_types', {})\n",
    "    \n",
    "    # Build description components\n",
    "    description_parts = []\n",
    "    \n",
    "    # Graph size\n",
    "    if node_count > 300:\n",
    "        description_parts.append(f\"Large code structure with {node_count} nodes\")\n",
    "    elif node_count > 100:\n",
    "        description_parts.append(f\"Medium-sized code structure with {node_count} nodes\")\n",
    "    else:\n",
    "        description_parts.append(f\"Small code structure with {node_count} nodes\")\n",
    "    \n",
    "    # Dangerous calls\n",
    "    if dangerous_calls:\n",
    "        if len(dangerous_calls) > 3:\n",
    "            description_parts.append(f\"multiple dangerous functions: {', '.join(dangerous_calls[:3])} and {len(dangerous_calls)-3} others\")\n",
    "        else:\n",
    "            description_parts.append(f\"dangerous functions: {', '.join(dangerous_calls)}\")\n",
    "    \n",
    "    # Control structures\n",
    "    call_count = vertex_types.get('CALL', 0)\n",
    "    control_count = vertex_types.get('CONTROL_STRUCTURE', 0)\n",
    "    \n",
    "    if control_count > 5:\n",
    "        description_parts.append(f\"complex control flow with {control_count} control structures\")\n",
    "    elif control_count > 0:\n",
    "        description_parts.append(f\"moderate control flow with {control_count} control structures\")\n",
    "    \n",
    "    if call_count > 20:\n",
    "        description_parts.append(f\"high function call density ({call_count} calls)\")\n",
    "    \n",
    "    return \"; \".join(description_parts) if description_parts else \"Simple code structure\"\n",
    "\n",
    "def generate_kb2_link_id(mapping: EnrichmentMapping) -> str:\n",
    "    \"\"\"\n",
    "    Generate KB2 link ID for cross-reference.\n",
    "    \"\"\"\n",
    "    return mapping.kb2_entry_key\n",
    "\n",
    "# Test field generation on sample mapping\n",
    "if kb1_kb2_mappings:\n",
    "    sample_mapping = kb1_kb2_mappings[0]\n",
    "    sample_kb1 = kb1_data[sample_mapping.kb1_cve_id]\n",
    "    sample_patterns = analyze_structural_patterns(sample_mapping.kb2_data)\n",
    "    \n",
    "    print(f\"\\nTesting field generation on: {sample_mapping.kb1_cve_id}\")\n",
    "    print(f\"KB2 link: {sample_mapping.kb2_entry_key}\")\n",
    "    print(f\"Dangerous calls found: {sample_patterns['dangerous_calls']}\")\n",
    "    print(f\"Generated vulnerability type: {generate_vulnerability_type(sample_kb1, sample_patterns)}\")\n",
    "    print(f\"Generated fix strategy: {generate_fix_strategy_type(sample_kb1, sample_patterns)}\")\n",
    "    print(f\"Generated complexity: {generate_complexity_level(sample_patterns)}\")\n",
    "    print(f\"Structural description: {generate_structural_description(sample_kb1, sample_patterns)[:100]}...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74e11ae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENRICHING KB1 WITH STRUCTURAL FIELDS\n",
      "========================================\n",
      "Enrichment completed:\n",
      "  Total entries: 2205\n",
      "  Enriched with KB2: 2205\n",
      "  Fallback only: 0\n",
      "  Enrichment rate: 100.0%\n",
      "\n",
      "Field distribution:\n",
      "  Vulnerability types: {'null_pointer_dereference': 529, 'race_condition': 521, 'use_after_free': 306, 'buffer_overflow': 277, 'injection': 153}\n",
      "  Fix strategies: {'bounds_checking': 1228, 'resource_management': 420, 'synchronization': 316, 'other': 126, 'null_checking': 74}\n",
      "  Complexity levels: {'simple': 1563, 'moderate': 629, 'complex': 13}\n",
      "\n",
      "Saving enriched KB1 to: /Users/vernetemmanueladjobi/Documents/RessourcesStages/Projets/VulRAG-Hybrid-System/data/processed/kb1\n",
      "  Saved: gpt-4o-mini_CWE-125_316_enriched.json (85 CVEs)\n",
      "  Saved: gpt-4o-mini_CWE-787_316_enriched.json (99 CVEs)\n",
      "  Saved: gpt-4o-mini_CWE-416_316_enriched.json (271 CVEs)\n",
      "  Saved: gpt-4o-mini_CWE-200_316_enriched.json (92 CVEs)\n",
      "  Saved: gpt-4o-mini_CWE-362_316_enriched.json (157 CVEs)\n",
      "  Saved: gpt-4o-mini_CWE-20_316_enriched.json (79 CVEs)\n",
      "  Saved: gpt-4o-mini_CWE-264_316_enriched.json (35 CVEs)\n",
      "  Saved: gpt-4o-mini_CWE-119_316_enriched.json (111 CVEs)\n",
      "  Saved: gpt-4o-mini_CWE-476_316_enriched.json (160 CVEs)\n",
      "  Saved: gpt-4o-mini_CWE-401_316_enriched.json (76 CVEs)\n",
      "  Saved: enrichment_summary.json\n",
      "\n",
      "Enrichment complete! 10 CWE files saved.\n",
      "\n",
      "KB1 ENRICHMENT COMPLETED SUCCESSFULLY\n",
      "========================================\n",
      "Original KB1 entries: 2205\n",
      "KB2-enhanced entries: 2205\n",
      "Output directory: /Users/vernetemmanueladjobi/Documents/RessourcesStages/Projets/VulRAG-Hybrid-System/data/processed/kb1\n",
      "Ready for hybrid RAG integration!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Cell 4: Batch Enrichment of KB1\n",
    "\n",
    "def enrich_kb1_entries(kb1_data: Dict, mappings: List[EnrichmentMapping]) -> Dict:\n",
    "    \"\"\"\n",
    "    Enrich all KB1 entries with 5 new fields using KB2 structural analysis.\n",
    "    \n",
    "    Returns:\n",
    "        Enriched KB1 data with new fields added\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"ENRICHING KB1 WITH STRUCTURAL FIELDS\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    enriched_kb1 = kb1_data.copy()\n",
    "    enrichment_stats = {\n",
    "        'total_entries': len(kb1_data),\n",
    "        'enriched_entries': 0,\n",
    "        'non_enriched_entries': 0,\n",
    "        'field_generation_stats': {\n",
    "            'vulnerability_types': Counter(),\n",
    "            'fix_strategies': Counter(),\n",
    "            'complexity_levels': Counter()\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Create mapping lookup for fast access\n",
    "    mapping_lookup = {mapping.kb1_cve_id: mapping for mapping in mappings}\n",
    "    \n",
    "    for kb1_key, kb1_entry in enriched_kb1.items():\n",
    "        if kb1_key in mapping_lookup:\n",
    "            # Has KB2 mapping - generate rich fields\n",
    "            mapping = mapping_lookup[kb1_key]\n",
    "            structural_patterns = analyze_structural_patterns(mapping.kb2_data)\n",
    "            \n",
    "            # Generate the 5 new fields\n",
    "            vulnerability_type = generate_vulnerability_type(kb1_entry, structural_patterns)\n",
    "            fix_strategy_type = generate_fix_strategy_type(kb1_entry, structural_patterns)\n",
    "            complexity_level = generate_complexity_level(structural_patterns)\n",
    "            structural_description = generate_structural_description(kb1_entry, structural_patterns)\n",
    "            kb2_link_id = generate_kb2_link_id(mapping)\n",
    "            \n",
    "            # Add new fields to KB1 entry\n",
    "            kb1_entry.update({\n",
    "                'structural_description': structural_description,\n",
    "                'vulnerability_type': vulnerability_type,\n",
    "                'fix_strategy_type': fix_strategy_type,\n",
    "                'complexity_level': complexity_level,\n",
    "                'kb2_link_id': kb2_link_id,\n",
    "                'enrichment_source': 'kb2_structural_analysis',\n",
    "                'enrichment_confidence': mapping.mapping_confidence\n",
    "            })\n",
    "            \n",
    "            # Update stats\n",
    "            enrichment_stats['enriched_entries'] += 1\n",
    "            enrichment_stats['field_generation_stats']['vulnerability_types'][vulnerability_type] += 1\n",
    "            enrichment_stats['field_generation_stats']['fix_strategies'][fix_strategy_type] += 1\n",
    "            enrichment_stats['field_generation_stats']['complexity_levels'][complexity_level] += 1\n",
    "            \n",
    "        else:\n",
    "            # No KB2 mapping - generate minimal fields from KB1 only\n",
    "            cwe = kb1_entry.get('source_cwe', '')\n",
    "            \n",
    "            # Basic fallback generation\n",
    "            vulnerability_type = {\n",
    "                'CWE-119': 'buffer_overflow',\n",
    "                'CWE-125': 'buffer_overflow',\n",
    "                'CWE-787': 'buffer_overflow',\n",
    "                'CWE-416': 'use_after_free',\n",
    "                'CWE-401': 'memory_leak',\n",
    "                'CWE-476': 'null_pointer_dereference',\n",
    "                'CWE-362': 'race_condition',\n",
    "                'CWE-20': 'input_validation',\n",
    "                'CWE-200': 'information_disclosure',\n",
    "                'CWE-264': 'privilege_escalation'\n",
    "            }.get(cwe, 'other')\n",
    "            \n",
    "            kb1_entry.update({\n",
    "                'structural_description': 'Structural analysis not available - textual analysis only',\n",
    "                'vulnerability_type': vulnerability_type,\n",
    "                'fix_strategy_type': 'other',\n",
    "                'complexity_level': 'unknown',\n",
    "                'kb2_link_id': None,\n",
    "                'enrichment_source': 'kb1_textual_fallback',\n",
    "                'enrichment_confidence': 0.5\n",
    "            })\n",
    "            \n",
    "            enrichment_stats['non_enriched_entries'] += 1\n",
    "    \n",
    "    # Print enrichment statistics\n",
    "    print(f\"Enrichment completed:\")\n",
    "    print(f\"  Total entries: {enrichment_stats['total_entries']}\")\n",
    "    print(f\"  Enriched with KB2: {enrichment_stats['enriched_entries']}\")\n",
    "    print(f\"  Fallback only: {enrichment_stats['non_enriched_entries']}\")\n",
    "    print(f\"  Enrichment rate: {enrichment_stats['enriched_entries']/enrichment_stats['total_entries']*100:.1f}%\")\n",
    "    \n",
    "    print(f\"\\nField distribution:\")\n",
    "    print(f\"  Vulnerability types: {dict(enrichment_stats['field_generation_stats']['vulnerability_types'].most_common(5))}\")\n",
    "    print(f\"  Fix strategies: {dict(enrichment_stats['field_generation_stats']['fix_strategies'].most_common(5))}\")\n",
    "    print(f\"  Complexity levels: {dict(enrichment_stats['field_generation_stats']['complexity_levels'])}\")\n",
    "    \n",
    "    return enriched_kb1, enrichment_stats\n",
    "\n",
    "def save_enriched_kb1(enriched_kb1: Dict, output_directory: Path) -> None:\n",
    "    \"\"\"\n",
    "    Save enriched KB1 data back to CWE-organized files.\n",
    "    \n",
    "    Preserves original KB1 structure while adding new fields.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"\\nSaving enriched KB1 to: {output_directory}\")\n",
    "    output_directory.mkdir(exist_ok=True)\n",
    "    \n",
    "    # Organize entries back by CWE\n",
    "    cwe_groups = {}\n",
    "    for kb1_key, kb1_entry in enriched_kb1.items():\n",
    "        cwe = kb1_entry.get('source_cwe', 'unknown')\n",
    "        if cwe not in cwe_groups:\n",
    "            cwe_groups[cwe] = {}\n",
    "        \n",
    "        # Extract original CVE_id for grouping\n",
    "        cve_id = kb1_entry.get('CVE_id', kb1_key)\n",
    "        instance_idx = kb1_entry.get('instance_index', 0)\n",
    "        \n",
    "        if cve_id not in cwe_groups[cwe]:\n",
    "            cwe_groups[cwe][cve_id] = []\n",
    "        \n",
    "        # Remove metadata fields before saving\n",
    "        clean_entry = {k: v for k, v in kb1_entry.items() \n",
    "                      if k not in ['source_cwe', 'instance_index', 'total_instances']}\n",
    "        \n",
    "        cwe_groups[cwe][cve_id].append(clean_entry)\n",
    "    \n",
    "    # Save each CWE file\n",
    "    saved_files = []\n",
    "    for cwe, cve_data in cwe_groups.items():\n",
    "        if cwe != 'unknown':\n",
    "            # Convert single-item lists back to single entries (preserve original format)\n",
    "            processed_data = {}\n",
    "            for cve_id, instances in cve_data.items():\n",
    "                if len(instances) == 1:\n",
    "                    processed_data[cve_id] = instances[0]\n",
    "                else:\n",
    "                    processed_data[cve_id] = instances\n",
    "            \n",
    "            output_file = output_directory / f\"gpt-4o-mini_{cwe}_316_enriched.json\"\n",
    "            with open(output_file, 'w') as f:\n",
    "                json.dump(processed_data, f, indent=2)\n",
    "            \n",
    "            saved_files.append(output_file.name)\n",
    "            print(f\"  Saved: {output_file.name} ({len(cve_data)} CVEs)\")\n",
    "    \n",
    "    # Save enrichment summary\n",
    "    summary_file = output_directory / \"enrichment_summary.json\"\n",
    "    summary_data = {\n",
    "        'enrichment_date': '2025-06-13',\n",
    "        'kb2_source': str(CONFIG['kb2_path']),\n",
    "        'total_cwe_files': len(saved_files),\n",
    "        'saved_files': saved_files,\n",
    "        'enrichment_stats': enrichment_stats\n",
    "    }\n",
    "    \n",
    "    with open(summary_file, 'w') as f:\n",
    "        json.dump(summary_data, f, indent=2)\n",
    "    \n",
    "    print(f\"  Saved: enrichment_summary.json\")\n",
    "    print(f\"\\nEnrichment complete! {len(saved_files)} CWE files saved.\")\n",
    "\n",
    "# Execute enrichment\n",
    "enriched_kb1, enrichment_stats = enrich_kb1_entries(kb1_data, kb1_kb2_mappings)\n",
    "save_enriched_kb1(enriched_kb1, CONFIG['output_directory'])\n",
    "\n",
    "print(f\"\\nKB1 ENRICHMENT COMPLETED SUCCESSFULLY\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"Original KB1 entries: {len(kb1_data)}\")\n",
    "print(f\"KB2-enhanced entries: {enrichment_stats['enriched_entries']}\")\n",
    "print(f\"Output directory: {CONFIG['output_directory']}\")\n",
    "print(f\"Ready for hybrid RAG integration!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vulrag_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
