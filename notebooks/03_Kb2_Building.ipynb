{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4a13ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INSPECTING GRAPHSON DATA STRUCTURE\n",
      "=============================================\n",
      "File: vuln_cpg.json\n",
      "Root keys: ['@type', '@value']\n",
      "124 vertices, 1095 edges\n",
      "\n",
      "VERTEX STRUCTURE:\n",
      "=========================\n",
      "Type: <class 'dict'>\n",
      "Keys: ['@type', 'id', 'label', 'properties']\n",
      "Full structure of the first vertex:\n",
      "{\n",
      "  \"@type\": \"g:Vertex\",\n",
      "  \"id\": {\n",
      "    \"@type\": \"g:Int64\",\n",
      "    \"@value\": 30064771075\n",
      "  },\n",
      "  \"label\": \"CALL\",\n",
      "  \"properties\": {\n",
      "    \"DISPATCH_TYPE\": {\n",
      "      \"@type\": \"g:VertexProperty\",\n",
      "      \"@value\": {\n",
      "        \"@type\": \"g:List\",\n",
      "        \"@value\": [\n",
      "          \"STATIC_DISPATCH\"\n",
      "        ]\n",
      "      },\n",
      "      \"id\": {\n",
      "        \"@type\": \"g:Int64\",\n",
      "        \"@value\": 3\n",
      "      }\n",
      "    },\n",
      "    \"NAME\": {\n",
      "      \"@type\": \"g:VertexProperty\",\n",
      "      \"@value\": {\n",
      "        \"@type\": \"g:List\",\n",
      "        \"@value\": [\n",
      "          \"<operator>.logicalOr\"\n",
      "        ]\n",
      "      },\n",
      "      \"id\": {\n",
      "        \"@type\": \"g:Int64\",\n",
      "        \"@value\": 6\n",
      "      }\n",
      "    },\n",
      "    \"METHOD_FULL_NAME\": {\n",
      "      \"@type\": \"g:VertexProperty\",\n",
      "      \"@value\": {\n",
      "        \"@type\": \"g:List\",\n",
      "        \"@value\": [\n",
      "          \"<operator>.logicalOr\"\n",
      "        ]\n",
      "      },\n",
      "      \"id\": {\n",
      "        \"@type\": \"g:Int64\",\n",
      "        \"@value\": 5\n",
      "      }\n",
      "    },\n",
      "    \"SIGNATURE\": {\n",
      "      \"@type\": \"g:VertexProperty\",\n",
      "      \"@value\": {\n",
      "        \"@type\": \"g:List\",\n",
      "        \"@value\": [\n",
      "         ...\n",
      "\n",
      "EDGE STRUCTURE:\n",
      "====================\n",
      "Type: <class 'dict'>\n",
      "Keys: ['@type', 'id', 'inV', 'inVLabel', 'label', 'outV', 'outVLabel', 'properties']\n",
      "Full structure of the first edge:\n",
      "{\n",
      "  \"@type\": \"g:Edge\",\n",
      "  \"id\": {\n",
      "    \"@type\": \"g:Int64\",\n",
      "    \"@value\": 0\n",
      "  },\n",
      "  \"inV\": {\n",
      "    \"@type\": \"g:Int64\",\n",
      "    \"@value\": 68719476765\n",
      "  },\n",
      "  \"inVLabel\": \"IDENTIFIER\",\n",
      "  \"label\": \"POST_DOMINATE\",\n",
      "  \"outV\": {\n",
      "    \"@type\": \"g:Int64\",\n",
      "    \"@value\": 30064771100\n",
      "  },\n",
      "  \"outVLabel\": \"CALL\",\n",
      "  \"properties\": {}\n",
      "}...\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Examine the REAL structure of the data\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "cpg_dir = Path.home() / \"Documents/RessourcesStages/Projets/VulRAG-Hybrid-System/data/tmp/cpg_json\"\n",
    "sample_file = list(cpg_dir.rglob(\"*vuln_cpg.json\"))[0]\n",
    "\n",
    "print(\"INSPECTING GRAPHSON DATA STRUCTURE\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "with open(sample_file) as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "print(f\"File: {sample_file.name}\")\n",
    "print(f\"Root keys: {list(data.keys())}\")\n",
    "\n",
    "vertices = data['@value']['vertices']\n",
    "edges = data['@value']['edges']\n",
    "\n",
    "print(f\"{len(vertices)} vertices, {len(edges)} edges\")\n",
    "\n",
    "# Examine ONE vertex in detail\n",
    "print(\"\\nVERTEX STRUCTURE:\")\n",
    "print(\"=\" * 25)\n",
    "first_vertex = vertices[0]\n",
    "print(f\"Type: {type(first_vertex)}\")\n",
    "print(f\"Keys: {list(first_vertex.keys()) if isinstance(first_vertex, dict) else 'Not a dict'}\")\n",
    "\n",
    "# Show the complete structure of the first vertex\n",
    "import json\n",
    "print(\"Full structure of the first vertex:\")\n",
    "print(json.dumps(first_vertex, indent=2)[:1000] + \"...\")\n",
    "\n",
    "# Examine ONE edge in detail  \n",
    "print(\"\\nEDGE STRUCTURE:\")\n",
    "print(\"=\" * 20)\n",
    "first_edge = edges[0]\n",
    "print(f\"Type: {type(first_edge)}\")\n",
    "print(f\"Keys: {list(first_edge.keys()) if isinstance(first_edge, dict) else 'Not a dict'}\")\n",
    "\n",
    "print(\"Full structure of the first edge:\")\n",
    "print(json.dumps(first_edge, indent=2)[:500] + \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885d0c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST CORRECTED EXTRACTION\n",
      "==============================\n",
      "\n",
      "VERTEX ANALYSIS:\n",
      "Vertex 1:\n",
      "  Label: CALL\n",
      "  Properties: ['DISPATCH_TYPE', 'NAME', 'METHOD_FULL_NAME', 'SIGNATURE', 'TYPE_FULL_NAME', 'COLUMN_NUMBER', 'ARGUMENT_INDEX', 'ORDER', 'CODE', 'LINE_NUMBER']\n",
      "  Name: <operator>.logicalOr\n",
      "  Method: <operator>.logicalOr\n",
      "\n",
      "Vertex 2:\n",
      "  Label: CALL\n",
      "  Properties: ['DISPATCH_TYPE', 'NAME', 'METHOD_FULL_NAME', 'SIGNATURE', 'TYPE_FULL_NAME', 'COLUMN_NUMBER', 'ARGUMENT_INDEX', 'ORDER', 'CODE', 'LINE_NUMBER']\n",
      "  Name: dput\n",
      "  Method: dput\n",
      "\n",
      "Vertex 3:\n",
      "  Label: IDENTIFIER\n",
      "  Properties: ['NAME', 'TYPE_FULL_NAME', 'COLUMN_NUMBER', 'ARGUMENT_INDEX', 'ORDER', 'CODE', 'LINE_NUMBER']\n",
      "  Name: new_dir\n",
      "\n",
      "Vertex 4:\n",
      "  Label: IDENTIFIER\n",
      "  Properties: ['NAME', 'TYPE_FULL_NAME', 'COLUMN_NUMBER', 'ARGUMENT_INDEX', 'ORDER', 'CODE', 'LINE_NUMBER']\n",
      "  Name: dentry\n",
      "\n",
      "Vertex 5:\n",
      "  Label: CALL\n",
      "  Properties: ['DISPATCH_TYPE', 'NAME', 'METHOD_FULL_NAME', 'SIGNATURE', 'TYPE_FULL_NAME', 'COLUMN_NUMBER', 'ARGUMENT_INDEX', 'ORDER', 'CODE', 'LINE_NUMBER']\n",
      "  Name: <operator>.assignment\n",
      "  Method: <operator>.assignment\n",
      "\n",
      "Vertex 6:\n",
      "  Label: BLOCK\n",
      "  Properties: ['TYPE_FULL_NAME', 'COLUMN_NUMBER', 'ARGUMENT_INDEX', 'ORDER', 'CODE', 'LINE_NUMBER']\n",
      "\n",
      "Vertex 7:\n",
      "  Label: CALL\n",
      "  Properties: ['DISPATCH_TYPE', 'NAME', 'METHOD_FULL_NAME', 'SIGNATURE', 'TYPE_FULL_NAME', 'COLUMN_NUMBER', 'ARGUMENT_INDEX', 'ORDER', 'CODE', 'LINE_NUMBER']\n",
      "  Name: d_really_is_negative\n",
      "  Method: d_really_is_negative\n",
      "\n",
      "Vertex 8:\n",
      "  Label: IDENTIFIER\n",
      "  Properties: ['NAME', 'TYPE_FULL_NAME', 'COLUMN_NUMBER', 'ARGUMENT_INDEX', 'ORDER', 'CODE', 'LINE_NUMBER']\n",
      "  Name: trap\n",
      "\n",
      "Vertex 9:\n",
      "  Label: IDENTIFIER\n",
      "  Properties: ['NAME', 'TYPE_FULL_NAME', 'COLUMN_NUMBER', 'ARGUMENT_INDEX', 'ORDER', 'CODE', 'LINE_NUMBER']\n",
      "  Name: old_dir\n",
      "\n",
      "Vertex 10:\n",
      "  Label: CALL\n",
      "  Properties: ['DISPATCH_TYPE', 'NAME', 'METHOD_FULL_NAME', 'SIGNATURE', 'TYPE_FULL_NAME', 'COLUMN_NUMBER', 'ARGUMENT_INDEX', 'ORDER', 'CODE', 'LINE_NUMBER']\n",
      "  Name: <operator>.assignment\n",
      "  Method: <operator>.assignment\n",
      "\n",
      "Vertex types found: {'IDENTIFIER', 'BLOCK', 'CALL'}\n",
      "Dangerous calls found: []\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: data extraction\n",
    "def extract_vertex_info(vertex):\n",
    "    \"\"\"Extract vertex info with the real GraphSON structure\"\"\"\n",
    "    info = {\n",
    "        'label': vertex.get('label', ''),\n",
    "        'properties': {}\n",
    "    }\n",
    "    \n",
    "    # Extract properties\n",
    "    if 'properties' in vertex:\n",
    "        for prop_name, prop_data in vertex['properties'].items():\n",
    "            if isinstance(prop_data, dict) and '@value' in prop_data:\n",
    "                value_data = prop_data['@value']\n",
    "                if isinstance(value_data, dict) and '@value' in value_data:\n",
    "                    # Structure: properties.NAME.@value.@value = [value]\n",
    "                    values = value_data['@value']\n",
    "                    if isinstance(values, list) and values:\n",
    "                        info['properties'][prop_name] = values[0]  # Take the first\n",
    "                    else:\n",
    "                        info['properties'][prop_name] = values\n",
    "    \n",
    "    return info\n",
    "\n",
    "def extract_edge_info(edge):\n",
    "    \"\"\"Extract edge info\"\"\"\n",
    "    return {\n",
    "        'label': edge.get('label', ''),\n",
    "        'from_type': edge.get('outVLabel', ''),\n",
    "        'to_type': edge.get('inVLabel', ''),\n",
    "        'from_id': edge.get('outV', {}).get('@value', '') if isinstance(edge.get('outV'), dict) else edge.get('outV', ''),\n",
    "        'to_id': edge.get('inV', {}).get('@value', '') if isinstance(edge.get('inV'), dict) else edge.get('inV', '')\n",
    "    }\n",
    "\n",
    "# Test on the first file\n",
    "sample_file = list(cpg_dir.rglob(\"*vuln_cpg.json\"))[0]\n",
    "\n",
    "with open(sample_file) as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "vertices = data['@value']['vertices']\n",
    "edges = data['@value']['edges']\n",
    "\n",
    "print(\"TEST  EXTRACTION\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "# Analyze the first vertices\n",
    "print(\"\\nVERTEX ANALYSIS:\")\n",
    "vertex_types = []\n",
    "vertex_names = []\n",
    "dangerous_calls = []\n",
    "\n",
    "dangerous_functions = ['strcpy', 'strcat', 'sprintf', 'scanf', 'gets', 'strncpy', \n",
    "                      'malloc', 'free', 'calloc', 'realloc', 'memcpy', 'memmove']\n",
    "\n",
    "for i, vertex in enumerate(vertices[:10]):\n",
    "    info = extract_vertex_info(vertex)\n",
    "    vertex_types.append(info['label'])\n",
    "    \n",
    "    print(f\"Vertex {i+1}:\")\n",
    "    print(f\"  Label: {info['label']}\")\n",
    "    print(f\"  Properties: {list(info['properties'].keys())}\")\n",
    "    \n",
    "    # Look for interesting names/calls\n",
    "    if 'NAME' in info['properties']:\n",
    "        name = info['properties']['NAME']\n",
    "        vertex_names.append(name)\n",
    "        print(f\"  Name: {name}\")\n",
    "        \n",
    "        # Check if it's a dangerous call\n",
    "        if info['label'] == 'CALL':\n",
    "            for dangerous in dangerous_functions:\n",
    "                if dangerous in str(name).lower():\n",
    "                    dangerous_calls.append(name)\n",
    "                    print(f\"  DANGEROUS CALL: {name}\")\n",
    "    \n",
    "    if 'METHOD_FULL_NAME' in info['properties']:\n",
    "        print(f\"  Method: {info['properties']['METHOD_FULL_NAME']}\")\n",
    "    \n",
    "    print()\n",
    "\n",
    "print(f\"Vertex types found: {set(vertex_types)}\")\n",
    "print(f\"Dangerous calls found: {dangerous_calls}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5257aef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FULL FILE ANALYSIS\n",
      "==============================\n",
      "File: vuln_cpg.json\n",
      "124 vertices, 1095 edges (790.5 KB)\n",
      "\n",
      "Vertex types:\n",
      "   IDENTIFIER: 47\n",
      "   CALL: 41\n",
      "   CONTROL_STRUCTURE: 9\n",
      "   BLOCK: 6\n",
      "   LOCAL: 5\n",
      "   METHOD_PARAMETER_OUT: 4\n",
      "   METHOD_PARAMETER_IN: 4\n",
      "   RETURN: 2\n",
      "   FIELD_IDENTIFIER: 2\n",
      "   METHOD: 1\n",
      "   LITERAL: 1\n",
      "   JUMP_TARGET: 1\n",
      "   METHOD_RETURN: 1\n",
      "\n",
      "Edge types (top 10):\n",
      "   REACHING_DEF: 315\n",
      "   AST: 123\n",
      "   CDG: 111\n",
      "   CFG: 110\n",
      "   CONTAINS: 109\n",
      "   POST_DOMINATE: 99\n",
      "   DOMINATE: 99\n",
      "   ARGUMENT: 73\n",
      "   REF: 47\n",
      "   CONDITION: 5\n",
      "\n",
      "Dangerous calls: {'fsnotify_oldname_free': 2}\n",
      "\n",
      "All calls (top 15):\n",
      "   <operator>.logicalOr: 5\n",
      "   <operator>.assignment: 5\n",
      "   d_inode: 4\n",
      "   d_really_is_negative: 3\n",
      "   dput: 2\n",
      "   fsnotify_oldname_free: 2\n",
      "   IS_ERR: 2\n",
      "   <operator>.equals: 2\n",
      "   unlock_rename: 2\n",
      "   <operator>.indirectFieldAccess: 1\n",
      "   fsnotify_oldname_init: 1\n",
      "   <operator>.logicalAnd: 1\n",
      "   fsnotify_move: 1\n",
      "   lookup_one_len: 1\n",
      "   lock_rename: 1\n",
      "\n",
      "Control structures: {'BLOCK': 6, 'CONTROL_STRUCTURE': 9}\n",
      "\n",
      "Top identifiers: {'dentry': 11, 'old_dentry': 9, 'new_dir': 7, 'old_dir': 6, 'old_name': 4, 'trap': 3, 'NULL': 3, 'new_name': 2}\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Full analysis of a CPG file \n",
    "def analyze_full_cpg(cpg_file):\n",
    "    \"\"\"Full analysis of a CPG file with the real structure\"\"\"\n",
    "    \n",
    "    with open(cpg_file) as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    vertices = data['@value']['vertices']\n",
    "    edges = data['@value']['edges']\n",
    "    \n",
    "    analysis = {\n",
    "        'file_info': {\n",
    "            'name': cpg_file.name,\n",
    "            'vertex_count': len(vertices),\n",
    "            'edge_count': len(edges),\n",
    "            'size_kb': cpg_file.stat().st_size / 1024\n",
    "        },\n",
    "        'vertex_types': {},\n",
    "        'edge_types': {},\n",
    "        'dangerous_calls': [],\n",
    "        'all_calls': [],\n",
    "        'methods': [],\n",
    "        'identifiers': [],\n",
    "        'literals': [],\n",
    "        'control_structures': []\n",
    "    }\n",
    "    \n",
    "    # Extended dangerous functions\n",
    "    dangerous_functions = [\n",
    "        'strcpy', 'strcat', 'sprintf', 'scanf', 'gets', 'strncpy',\n",
    "        'malloc', 'free', 'calloc', 'realloc', 'memcpy', 'memmove',\n",
    "        'memset', 'alloca', 'delete', 'new'\n",
    "    ]\n",
    "    \n",
    "    # Analyze all vertices\n",
    "    for vertex in vertices:\n",
    "        info = extract_vertex_info(vertex)\n",
    "        label = info['label']\n",
    "        \n",
    "        # Count types\n",
    "        analysis['vertex_types'][label] = analysis['vertex_types'].get(label, 0) + 1\n",
    "        \n",
    "        # Extract by type\n",
    "        if label == 'CALL' and 'NAME' in info['properties']:\n",
    "            name = info['properties']['NAME']\n",
    "            analysis['all_calls'].append(name)\n",
    "            \n",
    "            # Check if dangerous (flexible search)\n",
    "            name_lower = str(name).lower()\n",
    "            for dangerous in dangerous_functions:\n",
    "                if dangerous in name_lower:\n",
    "                    analysis['dangerous_calls'].append(name)\n",
    "                    break\n",
    "        \n",
    "        elif label == 'METHOD' and 'NAME' in info['properties']:\n",
    "            analysis['methods'].append(info['properties']['NAME'])\n",
    "        \n",
    "        elif label == 'IDENTIFIER' and 'NAME' in info['properties']:\n",
    "            analysis['identifiers'].append(info['properties']['NAME'])\n",
    "        \n",
    "        elif label == 'LITERAL' and 'CODE' in info['properties']:\n",
    "            analysis['literals'].append(info['properties']['CODE'])\n",
    "        \n",
    "        elif label in ['CONTROL_STRUCTURE', 'IF', 'FOR', 'WHILE', 'BLOCK']:\n",
    "            analysis['control_structures'].append(label)\n",
    "    \n",
    "    # Analyze all edges\n",
    "    for edge in edges:\n",
    "        edge_info = extract_edge_info(edge)\n",
    "        label = edge_info['label']\n",
    "        analysis['edge_types'][label] = analysis['edge_types'].get(label, 0) + 1\n",
    "    \n",
    "    # Deduplication and counting\n",
    "    from collections import Counter\n",
    "    analysis['dangerous_calls'] = dict(Counter(analysis['dangerous_calls']).most_common(10))\n",
    "    analysis['all_calls'] = dict(Counter(analysis['all_calls']).most_common(20))\n",
    "    analysis['methods'] = dict(Counter(analysis['methods']).most_common(10))\n",
    "    analysis['identifiers'] = dict(Counter(analysis['identifiers']).most_common(15))\n",
    "    analysis['control_structures'] = dict(Counter(analysis['control_structures']))\n",
    "    \n",
    "    return analysis\n",
    "\n",
    "# Analyze the sample file\n",
    "print(\"FULL FILE ANALYSIS\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "analysis = analyze_full_cpg(sample_file)\n",
    "\n",
    "print(f\"File: {analysis['file_info']['name']}\")\n",
    "print(f\"{analysis['file_info']['vertex_count']} vertices, {analysis['file_info']['edge_count']} edges ({analysis['file_info']['size_kb']:.1f} KB)\")\n",
    "\n",
    "print(f\"\\nVertex types:\")\n",
    "for vtype, count in sorted(analysis['vertex_types'].items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"   {vtype}: {count}\")\n",
    "\n",
    "print(f\"\\nEdge types (top 10):\")\n",
    "edge_items = sorted(analysis['edge_types'].items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "for etype, count in edge_items:\n",
    "    print(f\"   {etype}: {count}\")\n",
    "\n",
    "print(f\"\\nDangerous calls: {analysis['dangerous_calls']}\")\n",
    "print(f\"\\nAll calls (top 15):\")\n",
    "for call, count in list(analysis['all_calls'].items())[:15]:\n",
    "    print(f\"   {call}: {count}\")\n",
    "\n",
    "print(f\"\\nControl structures: {analysis['control_structures']}\")\n",
    "print(f\"\\nTop identifiers: {dict(list(analysis['identifiers'].items())[:8])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2cf8a8cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing CVE-2017-7533_0...\n",
      "\n",
      "VULNERABLE vs PATCH COMPARISON - CVE-2017-7533_0\n",
      "==================================================\n",
      "Vertices: 124 → 124 (+0)\n",
      "Edges: 1095 → 1103 (+8)\n",
      "\n",
      "Dangerous calls:\n",
      "   Removed: {'fsnotify_oldname_free'}\n",
      "   Added: set()\n",
      "   Unchanged: set()\n",
      "\n",
      "Function calls:\n",
      "   Removed: ['fsnotify_oldname_init', 'd_move', '<operator>.indirectFieldAccess', 'fsnotify_oldname_free', '<operator>.fieldAccess']\n",
      "   Added: ['simple_rename', 'release_dentry_name_snapshot', 'd_mountpoint', 'take_dentry_name_snapshot', '<operator>.addressOf']\n",
      "   Total vuln: 20, Total patch: 20\n",
      "\n",
      "Changes in vertex types:\n",
      "   CALL: 41 → 42 (+1)\n",
      "   FIELD_IDENTIFIER: 2 → 1 (-1)\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Vulnerable vs Patch Comparison\n",
    "def compare_vuln_vs_patch_corrected(instance_name):\n",
    "    \"\"\"Compare patterns between vulnerable and patched versions\"\"\"\n",
    "    \n",
    "    vuln_file = cpg_dir / instance_name / \"vuln_cpg.json\"\n",
    "    patch_file = cpg_dir / instance_name / \"patch_cpg.json\"\n",
    "    \n",
    "    if not (vuln_file.exists() and patch_file.exists()):\n",
    "        return None\n",
    "    \n",
    "    print(f\"Analyzing {instance_name}...\")\n",
    "    vuln_analysis = analyze_full_cpg(vuln_file)\n",
    "    patch_analysis = analyze_full_cpg(patch_file)\n",
    "    \n",
    "    # Compare basic metrics\n",
    "    comparison = {\n",
    "        'instance': instance_name,\n",
    "        'metrics_change': {\n",
    "            'vertices': {\n",
    "                'vuln': vuln_analysis['file_info']['vertex_count'],\n",
    "                'patch': patch_analysis['file_info']['vertex_count'],\n",
    "                'diff': patch_analysis['file_info']['vertex_count'] - vuln_analysis['file_info']['vertex_count']\n",
    "            },\n",
    "            'edges': {\n",
    "                'vuln': vuln_analysis['file_info']['edge_count'], \n",
    "                'patch': patch_analysis['file_info']['edge_count'],\n",
    "                'diff': patch_analysis['file_info']['edge_count'] - vuln_analysis['file_info']['edge_count']\n",
    "            }\n",
    "        },\n",
    "        'dangerous_calls': {\n",
    "            'vuln': set(vuln_analysis['dangerous_calls'].keys()),\n",
    "            'patch': set(patch_analysis['dangerous_calls'].keys()),\n",
    "        },\n",
    "        'all_calls': {\n",
    "            'vuln': set(vuln_analysis['all_calls'].keys()),\n",
    "            'patch': set(patch_analysis['all_calls'].keys()),\n",
    "        },\n",
    "        'vertex_types': {\n",
    "            'vuln': vuln_analysis['vertex_types'],\n",
    "            'patch': patch_analysis['vertex_types']\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Calculate differences\n",
    "    comparison['dangerous_calls']['removed'] = comparison['dangerous_calls']['vuln'] - comparison['dangerous_calls']['patch']\n",
    "    comparison['dangerous_calls']['added'] = comparison['dangerous_calls']['patch'] - comparison['dangerous_calls']['vuln']\n",
    "    comparison['dangerous_calls']['common'] = comparison['dangerous_calls']['vuln'] & comparison['dangerous_calls']['patch']\n",
    "    \n",
    "    comparison['all_calls']['removed'] = comparison['all_calls']['vuln'] - comparison['all_calls']['patch']\n",
    "    comparison['all_calls']['added'] = comparison['all_calls']['patch'] - comparison['all_calls']['vuln'] \n",
    "    comparison['all_calls']['common'] = comparison['all_calls']['vuln'] & comparison['all_calls']['patch']\n",
    "    \n",
    "    return comparison\n",
    "\n",
    "# Analyze the file we just examined\n",
    "instance_name = sample_file.parent.name\n",
    "comparison = compare_vuln_vs_patch_corrected(instance_name)\n",
    "\n",
    "if comparison:\n",
    "    print(f\"\\nVULNERABLE vs PATCH COMPARISON - {comparison['instance']}\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    metrics = comparison['metrics_change']\n",
    "    print(f\"Vertices: {metrics['vertices']['vuln']} → {metrics['vertices']['patch']} ({metrics['vertices']['diff']:+d})\")\n",
    "    print(f\"Edges: {metrics['edges']['vuln']} → {metrics['edges']['patch']} ({metrics['edges']['diff']:+d})\")\n",
    "    \n",
    "    dangerous = comparison['dangerous_calls']\n",
    "    print(f\"\\nDangerous calls:\")\n",
    "    print(f\"   Removed: {dangerous['removed']}\")\n",
    "    print(f\"   Added: {dangerous['added']}\")\n",
    "    print(f\"   Unchanged: {dangerous['common']}\")\n",
    "    \n",
    "    calls = comparison['all_calls']\n",
    "    print(f\"\\nFunction calls:\")\n",
    "    print(f\"   Removed: {list(calls['removed'])[:5]}\")\n",
    "    print(f\"   Added: {list(calls['added'])[:5]}\")\n",
    "    print(f\"   Total vuln: {len(calls['vuln'])}, Total patch: {len(calls['patch'])}\")\n",
    "    \n",
    "    # Differences in vertex types\n",
    "    vuln_types = comparison['vertex_types']['vuln']\n",
    "    patch_types = comparison['vertex_types']['patch']\n",
    "    \n",
    "    print(f\"\\nChanges in vertex types:\")\n",
    "    for vtype in set(vuln_types.keys()) | set(patch_types.keys()):\n",
    "        vuln_count = vuln_types.get(vtype, 0)\n",
    "        patch_count = patch_types.get(vtype, 0)\n",
    "        if vuln_count != patch_count:\n",
    "            print(f\"   {vtype}: {vuln_count} → {patch_count} ({patch_count - vuln_count:+d})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8ac00274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ANALYSIS OF MULTIPLE INSTANCES\n",
      "===================================\n",
      "Analyzing CVE-2017-7533_0...\n",
      "\n",
      "File: CVE-2017-7533_0:\n",
      "   Complexity change: +0 vertices, +8 edges\n",
      "   Dangerous calls - Removed: {'fsnotify_oldname_free'}, Added: set()\n",
      "   Calls changed: -5, +5\n",
      "Analyzing CVE-2021-0935_0...\n",
      "\n",
      "File: CVE-2021-0935_0:\n",
      "   Complexity change: +18 vertices, +153 edges\n",
      "   Dangerous calls - Removed: {'memset'}, Added: set()\n",
      "   No function calls changed\n",
      "Analyzing CVE-2017-14156_0...\n",
      "\n",
      "File: CVE-2017-14156_0:\n",
      "   Complexity change: +0 vertices, +0 edges\n",
      "   No dangerous calls changed\n",
      "   No function calls changed\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Analyze multiple instances to see patterns\n",
    "print(\"\\nANALYSIS OF MULTIPLE INSTANCES\")\n",
    "print(\"=\" * 35)\n",
    "\n",
    "# Take 3 different instances\n",
    "sample_instances = [f.parent.name for f in list(cpg_dir.rglob(\"*vuln_cpg.json\"))[:3]]\n",
    "\n",
    "for instance in sample_instances:\n",
    "    comparison = compare_vuln_vs_patch_corrected(instance)\n",
    "    if comparison:\n",
    "        print(f\"\\nFile: {instance}:\")\n",
    "        \n",
    "        metrics = comparison['metrics_change']\n",
    "        print(f\"   Complexity change: {metrics['vertices']['diff']:+d} vertices, {metrics['edges']['diff']:+d} edges\")\n",
    "        \n",
    "        dangerous = comparison['dangerous_calls']\n",
    "        if dangerous['removed'] or dangerous['added']:\n",
    "            print(f\"   Dangerous calls - Removed: {dangerous['removed']}, Added: {dangerous['added']}\")\n",
    "        else:\n",
    "            print(f\"   No dangerous calls changed\")\n",
    "        \n",
    "        calls = comparison['all_calls']\n",
    "        if calls['removed'] or calls['added']:\n",
    "            print(f\"   Calls changed: -{len(calls['removed'])}, +{len(calls['added'])}\")\n",
    "        else:\n",
    "            print(f\"   No function calls changed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ba346228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KB2 FEATURE EXTRACTION\n",
      "==============================\n",
      "File: vuln_cpg.json\n",
      "Basic metrics: 124 vertices, 1095 edges\n",
      "\n",
      "Security features:\n",
      "   Dangerous calls: {'fsnotify_oldname_free': 2}\n",
      "   Has malloc family: False\n",
      "   Has string functions: False\n",
      "   Has memory functions: True\n",
      "\n",
      "Code patterns:\n",
      "   Total unique calls: 20\n",
      "   Control structures: 15\n",
      "   Top calls: {'<operator>.logicalOr': 5, '<operator>.assignment': 5, 'd_inode': 4, 'd_really_is_negative': 3, 'dput': 2}\n",
      "\n",
      "Complexity:\n",
      "   Call density: 0.161\n",
      "   Edge density: 8.831\n",
      "   Control flow complexity: 15\n",
      "\n",
      "Signatures for retrieval:\n",
      "   Dangerous call signature: ['fsnotify_oldname_free']\n",
      "   Top calls signature: ['<operator>.assignment', '<operator>.equals', '<operator>.indirectFieldAccess', '<operator>.logicalOr', 'IS_ERR', 'd_inode', 'd_really_is_negative', 'dput', 'fsnotify_oldname_free', 'unlock_rename']\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Features for KB2 based on our findings\n",
    "def extract_kb2_features(cpg_file):\n",
    "    \"\"\"Extract optimal features for KB2 based on the analysis\"\"\"\n",
    "    \n",
    "    analysis = analyze_full_cpg(cpg_file)\n",
    "    \n",
    "    # Features based on our findings\n",
    "    features = {\n",
    "        # Basic metadata\n",
    "        'file_info': {\n",
    "            'source_file': cpg_file.name,\n",
    "            'size_kb': round(cpg_file.stat().st_size / 1024, 1),\n",
    "            'vertex_count': analysis['file_info']['vertex_count'],\n",
    "            'edge_count': analysis['file_info']['edge_count']\n",
    "        },\n",
    "        \n",
    "        # Critical security features\n",
    "        'security_features': {\n",
    "            'dangerous_calls': analysis['dangerous_calls'],\n",
    "            'dangerous_call_count': len(analysis['dangerous_calls']),\n",
    "            'has_malloc_family': any('malloc' in call or 'calloc' in call or 'realloc' in call \n",
    "                                   for call in analysis['all_calls'].keys()),\n",
    "            'has_string_functions': any(func in call.lower() \n",
    "                                      for call in analysis['all_calls'].keys()\n",
    "                                      for func in ['strcpy', 'strcat', 'sprintf', 'scanf']),\n",
    "            'has_memory_functions': any(func in call.lower()\n",
    "                                      for call in analysis['all_calls'].keys() \n",
    "                                      for func in ['memset', 'memcpy', 'memmove', 'free'])\n",
    "        },\n",
    "        \n",
    "        # Code patterns\n",
    "        'code_patterns': {\n",
    "            'all_calls': dict(list(analysis['all_calls'].items())[:20]),  # Top 20\n",
    "            'call_count': len(analysis['all_calls']),\n",
    "            'control_structure_count': sum(analysis['control_structures'].values()),\n",
    "            'identifier_count': len(analysis['identifiers']),\n",
    "            'vertex_type_distribution': analysis['vertex_types']\n",
    "        },\n",
    "        \n",
    "        # Structural complexity\n",
    "        'complexity_metrics': {\n",
    "            'call_to_vertex_ratio': len(analysis['all_calls']) / analysis['file_info']['vertex_count'] if analysis['file_info']['vertex_count'] > 0 else 0,\n",
    "            'edge_density': analysis['file_info']['edge_count'] / analysis['file_info']['vertex_count'] if analysis['file_info']['vertex_count'] > 0 else 0,\n",
    "            'control_flow_complexity': analysis['vertex_types'].get('CONTROL_STRUCTURE', 0) + analysis['vertex_types'].get('BLOCK', 0)\n",
    "        },\n",
    "        \n",
    "        # Signatures for retrieval\n",
    "        'signatures': {\n",
    "            'dangerous_call_signature': sorted(analysis['dangerous_calls'].keys()),\n",
    "            'top_calls_signature': sorted(list(analysis['all_calls'].keys())[:10]),\n",
    "            'vertex_type_signature': sorted([(k, v) for k, v in analysis['vertex_types'].items() if v > 2])\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return features\n",
    "\n",
    "# Test feature extraction on our sample\n",
    "print(\"KB2 FEATURE EXTRACTION\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "kb2_features = extract_kb2_features(sample_file)\n",
    "\n",
    "print(f\"File: {kb2_features['file_info']['source_file']}\")\n",
    "print(f\"Basic metrics: {kb2_features['file_info']['vertex_count']} vertices, {kb2_features['file_info']['edge_count']} edges\")\n",
    "\n",
    "print(\"\\nSecurity features:\")\n",
    "security = kb2_features['security_features']\n",
    "print(f\"   Dangerous calls: {security['dangerous_calls']}\")\n",
    "print(f\"   Has malloc family: {security['has_malloc_family']}\")\n",
    "print(f\"   Has string functions: {security['has_string_functions']}\")\n",
    "print(f\"   Has memory functions: {security['has_memory_functions']}\")\n",
    "\n",
    "print(\"\\nCode patterns:\")\n",
    "patterns = kb2_features['code_patterns']\n",
    "print(f\"   Total unique calls: {patterns['call_count']}\")\n",
    "print(f\"   Control structures: {patterns['control_structure_count']}\")\n",
    "print(f\"   Top calls: {dict(list(patterns['all_calls'].items())[:5])}\")\n",
    "\n",
    "print(\"\\nComplexity:\")\n",
    "complexity = kb2_features['complexity_metrics']\n",
    "print(f\"   Call density: {complexity['call_to_vertex_ratio']:.3f}\")\n",
    "print(f\"   Edge density: {complexity['edge_density']:.3f}\")\n",
    "print(f\"   Control flow complexity: {complexity['control_flow_complexity']}\")\n",
    "\n",
    "print(\"\\nSignatures for retrieval:\")\n",
    "sigs = kb2_features['signatures']\n",
    "print(f\"   Dangerous call signature: {sigs['dangerous_call_signature']}\")\n",
    "print(f\"   Top calls signature: {sigs['top_calls_signature']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "640def72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KB2 CONSTRUCTION - Estimated duration: 10-15 minutes\n",
      "Do you want to continue? (type 'yes' to confirm)\n",
      "\n",
      "TEST on 50 files first...\n",
      "Success: CVE-2017-7533_0_patch\n",
      "Success: CVE-2017-7533_0_vuln\n",
      "Success: CVE-2021-0935_0_patch\n",
      "Success: CVE-2021-0935_0_vuln\n",
      "Success: CVE-2017-14156_0_patch\n",
      "Success: CVE-2017-14156_0_vuln\n",
      "Success: CVE-2023-20928_3_patch\n",
      "Success: CVE-2023-20928_3_vuln\n",
      "Success: CVE-2019-15221_0_patch\n",
      "Success: CVE-2019-15221_0_vuln\n",
      "\n",
      "Test KB2: 10 entries created\n",
      "\n",
      "Example KB2 entry (CVE-2017-7533_0_patch):\n",
      "   CVE ID: CVE-2017-7533_0\n",
      "   Type: patch\n",
      "   Dangerous calls: {}\n",
      "   Complexity: 8.90\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Construction of KB2 for the entire dataset\n",
    "import json\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "def build_complete_kb2():\n",
    "    \"\"\"Build complete KB2 for all CPG files\"\"\"\n",
    "    \n",
    "    cpg_dir = Path.home() / \"Documents/RessourcesStages/Projets/VulRAG-Hybrid-System/data/tmp/cpg_json\"\n",
    "    kb2_output = Path.home() / \"Documents/RessourcesStages/Projets/VulRAG-Hybrid-System/data/tmp/kb2_complete.json\"\n",
    "    \n",
    "    print(\"CONSTRUCTION OF COMPLETE KB2\")\n",
    "    print(\"=\" * 35)\n",
    "    \n",
    "    # Find all CPG files\n",
    "    all_cpg_files = list(cpg_dir.rglob(\"*.json\"))\n",
    "    print(f\"Found {len(all_cpg_files)} CPG files to process\")\n",
    "    \n",
    "    kb2_data = {}\n",
    "    success_count = 0\n",
    "    error_count = 0\n",
    "    \n",
    "    # Process all files with progress bar\n",
    "    for cpg_file in tqdm(all_cpg_files, desc=\"Processing CPG files\"):\n",
    "        try:\n",
    "            # Extract CVE ID and type (vuln/patch)\n",
    "            instance_id = cpg_file.parent.name\n",
    "            file_type = 'vuln' if 'vuln_cpg' in cpg_file.name else 'patch'\n",
    "            entry_key = f\"{instance_id}_{file_type}\"\n",
    "            \n",
    "            # Extract features\n",
    "            features = extract_kb2_features(cpg_file)\n",
    "            \n",
    "            # Add metadata for KB2\n",
    "            kb2_entry = {\n",
    "                'cve_id': instance_id,\n",
    "                'file_type': file_type,\n",
    "                'features': features,\n",
    "                'extraction_success': True,\n",
    "                'extraction_date': '2025-06-13'\n",
    "            }\n",
    "            \n",
    "            kb2_data[entry_key] = kb2_entry\n",
    "            success_count += 1\n",
    "            \n",
    "        except Exception as e:\n",
    "            error_count += 1\n",
    "            print(f\"Error with {cpg_file}: {e}\")\n",
    "            \n",
    "            # Add error entry\n",
    "            kb2_data[f\"{cpg_file.parent.name}_{cpg_file.stem}\"] = {\n",
    "                'extraction_success': False,\n",
    "                'error': str(e),\n",
    "                'file_path': str(cpg_file)\n",
    "            }\n",
    "    \n",
    "    print(f\"\\nRESULTS:\")\n",
    "    print(f\"   Success: {success_count}\")\n",
    "    print(f\"   Errors: {error_count}\")\n",
    "    print(f\"   KB2 Entries: {len(kb2_data)}\")\n",
    "    \n",
    "    # Save KB2\n",
    "    print(f\"\\nSaving KB2...\")\n",
    "    with open(kb2_output, 'w') as f:\n",
    "        json.dump(kb2_data, f, indent=2)\n",
    "    \n",
    "    print(f\"KB2 saved: {kb2_output}\")\n",
    "    print(f\"File size: {kb2_output.stat().st_size / (1024*1024):.1f} MB\")\n",
    "    \n",
    "    return kb2_data, kb2_output\n",
    "\n",
    "# Start the construction\n",
    "# WARNING: This will take 10-15 minutes to process 4410 files\n",
    "print(\"KB2 CONSTRUCTION - Estimated duration: 10-15 minutes\")\n",
    "print(\"Do you want to continue? (type 'yes' to confirm)\")\n",
    "\n",
    "# For now, just test on 50 files\n",
    "test_files = list(cpg_dir.rglob(\"*.json\"))[:50]\n",
    "print(f\"\\nTEST on {len(test_files)} files first...\")\n",
    "\n",
    "kb2_test = {}\n",
    "for cpg_file in test_files[:10]:  # Just 10 for now\n",
    "    try:\n",
    "        instance_id = cpg_file.parent.name\n",
    "        file_type = 'vuln' if 'vuln_cpg' in cpg_file.name else 'patch'\n",
    "        entry_key = f\"{instance_id}_{file_type}\"\n",
    "        \n",
    "        features = extract_kb2_features(cpg_file)\n",
    "        kb2_test[entry_key] = {\n",
    "            'cve_id': instance_id,\n",
    "            'file_type': file_type,\n",
    "            'features': features\n",
    "        }\n",
    "        print(f\"Success: {entry_key}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {cpg_file.name}: {e}\")\n",
    "\n",
    "print(f\"\\nTest KB2: {len(kb2_test)} entries created\")\n",
    "\n",
    "# Show an example KB2 entry\n",
    "if kb2_test:\n",
    "    sample_key = list(kb2_test.keys())[0]\n",
    "    sample_entry = kb2_test[sample_key]\n",
    "    print(f\"\\nExample KB2 entry ({sample_key}):\")\n",
    "    print(f\"   CVE ID: {sample_entry['cve_id']}\")\n",
    "    print(f\"   Type: {sample_entry['file_type']}\")\n",
    "    print(f\"   Dangerous calls: {sample_entry['features']['security_features']['dangerous_calls']}\")\n",
    "    print(f\"   Complexity: {sample_entry['features']['complexity_metrics']['edge_density']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "63914474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LAUNCHING FULL KB2 CONSTRUCTION\n",
      "You can continue working while this runs...\n",
      "CONSTRUCTION OF COMPLETE KB2\n",
      "===================================\n",
      "Found 4410 CPG files to process\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing CPG files: 100%|██████████| 4410/4410 [00:32<00:00, 136.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RESULTS:\n",
      "   Success: 4410\n",
      "   Errors: 0\n",
      "   KB2 Entries: 4410\n",
      "\n",
      "Saving KB2...\n",
      "KB2 saved: /Users/vernetemmanueladjobi/Documents/RessourcesStages/Projets/VulRAG-Hybrid-System/data/tmp/kb2_complete.json\n",
      "File size: 11.2 MB\n"
     ]
    }
   ],
   "source": [
    "# Full KB2 construction in background\n",
    "print(\"LAUNCHING FULL KB2 CONSTRUCTION\")\n",
    "print(\"You can continue working while this runs...\")\n",
    "\n",
    "# In tmux or as a background process\n",
    "kb2_data, kb2_file = build_complete_kb2()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vulrag_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
